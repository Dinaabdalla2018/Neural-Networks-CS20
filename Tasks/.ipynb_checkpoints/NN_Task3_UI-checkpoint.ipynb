{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfFHnt1nPLti"
   },
   "source": [
    "<h1>Task 3</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZtYDESXlPLtU"
   },
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8Yw_2fiPLta"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjXTNbSqPLte"
   },
   "source": [
    "## Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7T1Bmo6tPLtf"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('IrisData.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid_derivative(x):\n",
    "    f = 1.0 / (1.0 + math.exp(-x))\n",
    "    return (f * (1.0 - f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Tangent activation function\n",
    "def tanh_derivative(x):\n",
    "    f = (2.0/(1.0 + np.exp(-2.0*x))-1.0)\n",
    "    return (1.0 - (f**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return (2.0/(1.0 + np.exp(-2.0*x))-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the neural network layers\n",
    "\n",
    "- Each layer consists of an input matrix, a weight matrix and an error list.\n",
    "\n",
    "    - The Input layer, is the x_train or test matrix.\n",
    "\n",
    "    - The output layer, is a (3, 1) matirx.\n",
    "    \n",
    "    - For each of the hidden layers the dimensions are (numOf neurons in this layer, numOf neurons in the previous layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network contains layers in the form of dictionaries, each layer consists of:\n",
    "# numpy array of layer weights.\n",
    "# numpy array of layer inputs.\n",
    "# net value.\n",
    "# gradient value.\n",
    "# All values are randomly intialized.\n",
    "def nn_setup(numOf_hidden_Layers, numOf_neurons):\n",
    "    # adding the number of neurons of the input layer\n",
    "    numOf_neurons.insert(0, data.shape[1])\n",
    "    # a list of dictionaries of numpy arrays, holding the layers weights, inputs, net and gradient value.\n",
    "    network = list()\n",
    "    input_layer   = {'weights':  np.random.rand(numOf_neurons[0]),\n",
    "                     'inputs': np.random.rand(numOf_neurons[0]), \n",
    "                     'net': np.random.rand(numOf_neurons[0], 1), \n",
    "                     'gradient': np.random.rand(numOf_neurons[0], 1)}\n",
    "    input_layer['weights'] = input_layer['weights'].reshape(input_layer['weights'].shape[0], 1)\n",
    "    input_layer['inputs'] = input_layer['inputs'].reshape(input_layer['inputs'].shape[0], 1)\n",
    "    \n",
    "    hidden_layers = [{'weights': np.random.rand(numOf_neurons[i], numOf_neurons[i - 1]),\n",
    "                      'inputs': np.random.rand(numOf_neurons[i], numOf_neurons[i - 1]), \n",
    "                      'net': np.random.rand(numOf_neurons[i], 1), \n",
    "                      'gradient': np.random.rand(numOf_neurons[i], 1)} for i in range(1, len(numOf_neurons))]\n",
    "    \n",
    "    output_layer  = {'weights':  np.random.rand(4, numOf_neurons[-1]),\n",
    "                     'inputs': np.random.rand(4, numOf_neurons[-1]), \n",
    "                     'net': np.random.rand(4, 1), \n",
    "                     'gradient': np.random.rand(4, 1)}\n",
    "    \n",
    "    network.append(input_layer)\n",
    "    network += hidden_layers\n",
    "    network.append(output_layer)\n",
    "    #print(network)\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Backpropagation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First feed forward function\n",
    "\n",
    "- use vector/matrix multiplication to calculate net value on each layer.\n",
    "    - net  = sum(dot(layer_x, W.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network contains layers in the form of dictionaries, each layer consists of:\n",
    "# numpy array of layer weights.\n",
    "# numpy array of layer inputs.\n",
    "# net value.\n",
    "# gradient value.\n",
    "# All values are randomly intialized.\n",
    "def feed_forward1(network, input_row, activation_fn, use_bias):\n",
    "    # for each layer use vector/matrix multiplication to calculate the net value and update it in the network.\n",
    "    network[0]['inputs'] = input_row.reshape(input_row.shape[0], 1)\n",
    "    network[1]['inputs'] = input_row.reshape(input_row.shape[0], 1)\n",
    "    last_output = []\n",
    "    for i in range(1, len(network)):\n",
    "        #if not use_bias:\n",
    "        #    network[i]['weights'][:][0] = np.zeros(network[i]['weights'].shape[1])\n",
    "        # calculate the product of the current layer's weights and inputs.\n",
    "        neurons_val = np.dot(network[i]['weights'], network[i]['inputs'])\n",
    "        \n",
    "        # calculate the net value.\n",
    "        network[i]['net'] = neurons_val\n",
    "        \n",
    "        # apply the activation function on the cur neurons values to get their output.\n",
    "        if activation_fn == 'Sigmoid':\n",
    "            neurons_val = [sigmoid(val) for val in neurons_val]\n",
    "        else:\n",
    "            neurons_val = [tanh(val) for val in neurons_val]\n",
    "        \n",
    "        # the next layer input is this layer's output\n",
    "        if i < len(network) - 1:\n",
    "            network[i + 1]['inputs'] = np.array(neurons_val).reshape(-1, 1)\n",
    "        else:\n",
    "            last_output = [1 if max(neurons_val[1:]) is neurons_val[i] else 0 for i in range(1, len(neurons_val))]\n",
    "            last_output.insert(0, 1)\n",
    "\n",
    "    return network, last_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First feed backward function\n",
    "\n",
    "- use vector/matrix multiplication to calculate gradient value on each layer.\n",
    "    - Output_layer_gradient = (intended_y - predicted_y) * d_activation_fn(net)\n",
    "    - Hidden_layer_gradient_i = (gradient_(i-1) * W_i * d_activation_fn(net_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef feed_backward(network, intended_y, predicted_y, activation_fn):\\n    # for each layer use vector/matrix multiplication to calculate the gradient value and update it in the network.\\n    # calculating gradient for output layer\\n    output_layer = network[len(network) - 1]\\n    output_layer['gradient'] = intended_y - predicted_y\\n    if activation_fn is 'Sigmoid':\\n        deriv = [sigmoid_derivative(val) for val in output_layer['net']]\\n    else:\\n        deriv = [tanh_derivative(val) for val in output_layer['net']]\\n    deriv = np.array(deriv).reshape(-1, 1)\\n    net = np.array(output_layer['net']).reshape(-1, 1)\\n    output_layer['gradient'].flatten()\\n    output_layer['gradient'] = output_layer['gradient'].reshape(-1, 1)\\n    output_layer['gradient'] = output_layer['gradient'] * deriv\\n    #np.dot(output_layer['gradient'], net)\\n    network[len(network) - 1] = output_layer\\n    print(len(network))\\n    # calculating gradient for hidden layers\\n    previous_gradient = output_layer['gradient']\\n    for i in range(len(network) - 2, -1, -1): # step=-1\\n        layer = network[i]\\n        next_layer = network[i + 1]\\n        #print('prev gradient', previous_gradient.shape)\\n        #print('weights', next_layer['weights'].shape)\\n        layer['gradient'] = np.dot(next_layer['weights'].T, next_layer['gradient'])\\n        if activation_fn is 'Sigmoid':\\n            deriv = [sigmoid_derivative(val) for val in layer['net']]\\n        else:\\n            deriv = [tanh_derivative(val) for val in layer['net']]\\n        deriv = np.array(deriv).reshape(-1, 1)\\n        net = np.array(layer['net']).reshape(-1, 1)\\n        #print('gradient', layer['gradient'].shape)\\n        #print('deriv', deriv.shape)\\n        layer['gradient'].flatten()\\n        #print('flatten gradient', layer['gradient'].shape)\\n        #print('\\n')\\n        layer['gradient'] = layer['gradient'] * deriv\\n        print('\\n')\\n        print('Network', i)\\n        print('cur grad', layer['gradient'])\\n        print('prev grad', next_layer['gradient'])\\n        print('weights', next_layer['weights'])\\n        print('deriv', deriv)\\n        #np.dot(layer['gradient'], net)\\n        network[i]['gradient'] = layer['gradient']  \\n        previous_gradient = layer['gradient']\\n    #print('backward net', network[1]['net'])\\n    return network\\n    \""
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network contains layers in the form of dictionaries, each layer consists of:\n",
    "# numpy array of layer weights.\n",
    "# numpy array of layer inputs.\n",
    "# net value.\n",
    "# gradient value.\n",
    "# All values are randomly intialized.\n",
    "def feed_backward(network, intended_y, predicted_y, activation_fn):\n",
    "    # for each layer use vector/matrix multiplication to calculate the gradient value and update it in the network.\n",
    "    # calculating gradient for output layer\n",
    "    output_layer = network[-1]\n",
    "    # clalculate the error cost between the predicted and the intended values.\n",
    "    output_layer['gradient'] = intended_y - predicted_y\n",
    "    \n",
    "    # calculate the derivative activation of each net value.\n",
    "    if activation_fn == 'Sigmoid':\n",
    "        deriv = [sigmoid_derivative(val) for val in output_layer['net']]\n",
    "    else:\n",
    "        deriv = [tanh_derivative(val) for val in output_layer['net']]\n",
    "    \n",
    "    # reshaping for multiplication\n",
    "    output_layer['gradient'].flatten()\n",
    "    deriv = np.array(deriv).reshape(-1, 1)\n",
    "    output_layer['gradient'] = output_layer['gradient'].reshape(-1, 1)\n",
    "    \n",
    "    # clalulating the output gradient = (intended_y - predicted_y) * acyivation_derivative(output_net_values)\n",
    "    output_layer['gradient'] = output_layer['gradient'] * deriv\n",
    "    #updating the gradient value in the network\n",
    "    network[len(network) - 1]['gradient'] =  output_layer['gradient']\n",
    "    #print('grad', network[-1]['gradient'])\n",
    "    \n",
    "    # for each hidden layer, starting from the last one\n",
    "    for i in range(len(network) - 2, 0, -1):\n",
    "        # calculate the derivative activation of each net value.\n",
    "        if activation_fn is 'Sigmoid':\n",
    "            deriv = [sigmoid_derivative(val) for val in network[i]['net']]\n",
    "        else:\n",
    "            deriv = [tanh_derivative(val) for val in network[i]['net']]\n",
    "        \n",
    "        # reshaping for multiplication\n",
    "        deriv = np.array(deriv).reshape(-1, 1)\n",
    "        # calculating the sum of neuron weights between this layer and the previous one multiplied by the previous gradient.\n",
    "        network[i]['gradient'] = np.dot(network[i + 1]['weights'].T, network[i + 1]['gradient']) * deriv\n",
    "        #print('grad', network[i]['gradient'])\n",
    "    return network\n",
    "\"\"\"\n",
    "def feed_backward(network, intended_y, predicted_y, activation_fn):\n",
    "    # for each layer use vector/matrix multiplication to calculate the gradient value and update it in the network.\n",
    "    # calculating gradient for output layer\n",
    "    output_layer = network[len(network) - 1]\n",
    "    output_layer['gradient'] = intended_y - predicted_y\n",
    "    if activation_fn is 'Sigmoid':\n",
    "        deriv = [sigmoid_derivative(val) for val in output_layer['net']]\n",
    "    else:\n",
    "        deriv = [tanh_derivative(val) for val in output_layer['net']]\n",
    "    deriv = np.array(deriv).reshape(-1, 1)\n",
    "    net = np.array(output_layer['net']).reshape(-1, 1)\n",
    "    output_layer['gradient'].flatten()\n",
    "    output_layer['gradient'] = output_layer['gradient'].reshape(-1, 1)\n",
    "    output_layer['gradient'] = output_layer['gradient'] * deriv\n",
    "    #np.dot(output_layer['gradient'], net)\n",
    "    network[len(network) - 1] = output_layer\n",
    "    print(len(network))\n",
    "    # calculating gradient for hidden layers\n",
    "    previous_gradient = output_layer['gradient']\n",
    "    for i in range(len(network) - 2, -1, -1): # step=-1\n",
    "        layer = network[i]\n",
    "        next_layer = network[i + 1]\n",
    "        #print('prev gradient', previous_gradient.shape)\n",
    "        #print('weights', next_layer['weights'].shape)\n",
    "        layer['gradient'] = np.dot(next_layer['weights'].T, next_layer['gradient'])\n",
    "        if activation_fn is 'Sigmoid':\n",
    "            deriv = [sigmoid_derivative(val) for val in layer['net']]\n",
    "        else:\n",
    "            deriv = [tanh_derivative(val) for val in layer['net']]\n",
    "        deriv = np.array(deriv).reshape(-1, 1)\n",
    "        net = np.array(layer['net']).reshape(-1, 1)\n",
    "        #print('gradient', layer['gradient'].shape)\n",
    "        #print('deriv', deriv.shape)\n",
    "        layer['gradient'].flatten()\n",
    "        #print('flatten gradient', layer['gradient'].shape)\n",
    "        #print('\\n')\n",
    "        layer['gradient'] = layer['gradient'] * deriv\n",
    "        print('\\n')\n",
    "        print('Network', i)\n",
    "        print('cur grad', layer['gradient'])\n",
    "        print('prev grad', next_layer['gradient'])\n",
    "        print('weights', next_layer['weights'])\n",
    "        print('deriv', deriv)\n",
    "        #np.dot(layer['gradient'], net)\n",
    "        network[i]['gradient'] = layer['gradient']  \n",
    "        previous_gradient = layer['gradient']\n",
    "    #print('backward net', network[1]['net'])\n",
    "    return network\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second feed forward function\n",
    "\n",
    "- use vector/matrix multiplication to Update the weight matrix in each layer.\n",
    "    - W_i = W_i + (learning_rate * gradient_i * x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndef feed_forward2(network, learning_rate):\\n     # for each layer use vector/matrix multiplication to calculate the new weights value and update it in the network.\\n    for i in range (1 , len(network)):\\n        layer = network[i]\\n        \\n        for neuron_index in range(layer['weights'].shape[0]):\\n            layer['weights'][neuron_index] += (layer['inputs'] * layer['gradient'][neuron_index]) * learning_rate\\n        \\n        network[i] = layer\\n        \\n    return network\\n\""
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network contains layers in the form of dictionaries, each layer consists of:\n",
    "# numpy array of layer weights.\n",
    "# numpy array of layer inputs.\n",
    "# net value.\n",
    "# gradient value.\n",
    "# All values are randomly intialized.\n",
    "\n",
    "def feed_forward2(network, learning_rate):\n",
    "    # for each layer use vector/matrix multiplication to calculate the new weights value and update it in the network.\n",
    "    #print('learning rate:', learning_rate)\n",
    "    for i in range (1 , len(network)):\n",
    "        #print('layer', i)\n",
    "        layer = network[i]\n",
    "        cur_weights = layer['weights']\n",
    "        \n",
    "        # updating the weights with the given input\n",
    "        for j in range(layer['weights'].shape[0]):\n",
    "            addval = (layer['inputs'] * learning_rate * layer['gradient'][j])\n",
    "            #print('addval', addval)\n",
    "            #print('weights_i_j befor', cur_weights[j])\n",
    "            cur_weights[j] = [float(cur_weights[j][k] + addval[k]) for k in range(len(addval))]\n",
    "            #print('weights_i_j after', cur_weights[j])\n",
    "        \n",
    "        network[i]['gradient'] = np.array(cur_weights)\n",
    "        \n",
    "    return network\n",
    "\"\"\"\n",
    "\n",
    "def feed_forward2(network, learning_rate):\n",
    "     # for each layer use vector/matrix multiplication to calculate the new weights value and update it in the network.\n",
    "    for i in range (1 , len(network)):\n",
    "        layer = network[i]\n",
    "        \n",
    "        for neuron_index in range(layer['weights'].shape[0]):\n",
    "            layer['weights'][neuron_index] += (layer['inputs'] * layer['gradient'][neuron_index]) * learning_rate\n",
    "        \n",
    "        network[i] = layer\n",
    "        \n",
    "    return network\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation model\n",
    "\n",
    "- For each epoch call:\n",
    "\n",
    "    - Feed forward, calculating the net values for each layer.\n",
    "\n",
    "    - Feed Backward, calculating the gradient values for each layer.\n",
    "\n",
    "    - Feed forward, updating the weights for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(x_train, y_train, network, learning_rate, epochs, use_bias, activation_fn):\n",
    "    network3 = network\n",
    "    # for each epoch:\n",
    "    for i in range(epochs):\n",
    "        sum_error = 0\n",
    "        for ind in range(x_train.shape[0]):\n",
    "            # call feed_forward1 with the given network, row of data, activation function and use_bias.\n",
    "            network1, y_prediction = feed_forward1(network3, x_train[ind], activation_fn, use_bias)\n",
    "            # calculating the sum squared error of prediction in each epoch\n",
    "            sum_error += sum([(y_train[ind][i]-y_prediction[i])**2 for i in range(len(y_prediction))])\n",
    "            # call feed_backward with the returned network, cur row of y_train, cur y_prediction for this row and the activation_fn\n",
    "            network2 = feed_backward(network1, y_train[ind], np.array(y_prediction), activation_fn)\n",
    "            # call feed_forward2 with the returned network and other necessary values\n",
    "            #print('weights before for2', network[2]['weights'])\n",
    "            network3 = feed_forward2(network2, learning_rate)\n",
    "            #print('weights after for2', network[2]['weights'])\n",
    "        print(\"epoch:\", i)\n",
    "        #print(\"network:\", network)\n",
    "        print(\"sum square error:\", sum_error)\n",
    "    return network3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_test, y_test, network, activation_fn, use_bias):\n",
    "    y_prediction = []\n",
    "    for row in x_test:\n",
    "        network1, y = feed_forward1(network, row, activation_fn, use_bias)\n",
    "        y_prediction.append(y)\n",
    "    print(y_prediction)\n",
    "    # calculating the accuracy.\n",
    "    comparison = (y_prediction == y_test)\n",
    "    co = 0\n",
    "    for l in comparison:\n",
    "        ans = True\n",
    "        for val in l:\n",
    "            ans &= val\n",
    "        if ans == True:\n",
    "            co += 1\n",
    "    accuracy = (co/y_test.shape[0]) * 100\n",
    "    return y_prediction, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwxUH6jbPLuO"
   },
   "outputs": [],
   "source": [
    "# We will be using all the 4 feauters and 3 classes.\n",
    "# The y column should be on hot encoded, meaning that if the label is c1 \n",
    "    # then it should be represented as follow, 100 and so on.\n",
    "\n",
    "def extract_data():\n",
    "    data_x = data.iloc[:, :4]\n",
    "    x0 = np.ones([150, 1]) # feature 0 for bias\n",
    "    data_x = np.append(x0, data_x, axis=1)\n",
    "    # One hot encoding the ouput column.\n",
    "    values = np.array(data['Class'])\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    data_y = onehot_encoded\n",
    "    data_y = np.append(x0, data_y, axis=1)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.4, shuffle=True, stratify = data_y)\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pl9GMxsjPLuT"
   },
   "outputs": [],
   "source": [
    "def main(numOf_hidden_layers, numOf_nuerons, activation_fn, learning_rate, epochs, use_bias):\n",
    "    print(activation_fn)\n",
    "    # Get the train and test data.\n",
    "    x_train, y_train, x_test, y_test = extract_data()\n",
    "\n",
    "    # Setup the Neural Network layer.\n",
    "    network = nn_setup(numOf_hidden_layers, numOf_nuerons)\n",
    "    \n",
    "    #print('original', network)\n",
    "    \n",
    "    # Call the backpropagation model and return the learned weights.\n",
    "    network1 = backpropagation(x_train, y_train, network, learning_rate, epochs, use_bias, activation_fn)\n",
    "\n",
    "    #print(network)\n",
    "    \n",
    "    # Test the moddel and return its accuracy, then print it.\n",
    "    y_prediction_test, accuracy_test = test(x_test, y_test, network1, activation_fn, use_bias)\n",
    "    print('Testing accuracy:\\n', accuracy_test)\n",
    "    \n",
    "    # print the confusion matrix.\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_prediction_test))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h1>UI</h1>\n",
    "\n",
    "- text box to take the number of desired hidden layers.\n",
    "\n",
    "- text box to take the number of desired neurons in each hidden layer.\n",
    "\n",
    "- combo box to choose the activation function, sigmoid or tanh.\n",
    "\n",
    "- text box to take the desired learning rate.\n",
    "\n",
    "- text box to take the desired number of epochs.\n",
    "\n",
    "- check box for the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "input_window = Tk()\n",
    "input_window.title(\"Neural Networks Task 3\")\n",
    "input_window.geometry(\"500x500\")\n",
    "activation_fns = [\"Sigmoid\", \"Tanh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Number of Hidden Layers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of hidden Layers label\n",
    "numOf_hidden_layers_value = StringVar()\n",
    "numOf_hidden_layers_label = Label(input_window, textvariable = numOf_hidden_layers_value) \n",
    "numOf_hidden_layers_value.set(\"Number of hidden Layers\")\n",
    "numOf_hidden_layers_label.place(x=45, y=100)\n",
    "#Number of hidden Layers text\n",
    "numOf_hidden_layers_text = Entry(input_window)\n",
    "numOf_hidden_layers_text.place(x=190, y=100)\n",
    "numOf_hidden_layers_text.focus_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Number of neurons in each hidden layer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of neurons hidden Layers label\n",
    "numOf_neurons_value = StringVar()\n",
    "numOf_neurons_label = Label(input_window, textvariable = numOf_neurons_value) \n",
    "numOf_neurons_value.set(\"Number of neurons in them\")\n",
    "numOf_neurons_label.place(x=30, y=140)\n",
    "#Number of neurons hidden Layers text\n",
    "numOf_neurons_text = Entry(input_window)\n",
    "numOf_neurons_text.place(x=190, y=140)\n",
    "numOf_neurons_text.focus_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Activation function Dropdown List</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "#Activation fn label\n",
    "activation_fn_value = StringVar()\n",
    "activation_fn_label = Label(input_window, textvariable = activation_fn_value) \n",
    "activation_fn_value.set(\"Activaion function\")\n",
    "activation_fn_label.place(x=80, y=170)\n",
    "#Activation fn list\n",
    "activation_fn_var = StringVar(input_window)\n",
    "activation_fn = OptionMenu(input_window, activation_fn_var, *activation_fns)\n",
    "activation_fn.config(width=12, font=('Helvetica', 10))\n",
    "#activation_fn_var.set('Sigmoid') # set the default option\n",
    "activation_fn.place(x=190, y=170)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Learning Rate</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "#learning rate label\n",
    "learning_rate_value = StringVar()\n",
    "learning_rate_label = Label(input_window, textvariable = learning_rate_value) \n",
    "learning_rate_value.set(\"Learning Rate\")\n",
    "learning_rate_label.place(x=105, y=210)\n",
    "#learning rate text\n",
    "learning_rate_text = Entry(input_window)\n",
    "learning_rate_text.place(x=193, y=210)\n",
    "learning_rate_text.focus_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Epochs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "#Epochs label\n",
    "epochs_label_value = StringVar()\n",
    "epochs_label = Label(input_window, textvariable = epochs_label_value) \n",
    "epochs_label_value.set(\"Epochs\")\n",
    "epochs_label.place(x=140, y=240)\n",
    "#Epochs text\n",
    "epochs_text = Entry(input_window)\n",
    "epochs_text.place(x=193, y=240)\n",
    "epochs_text.focus_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Bias</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "#Bias check box\n",
    "bias_checkbox = IntVar()\n",
    "Checkbutton(input_window, text=\"Bias\", variable=bias_checkbox).place(x=190,y=290)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Training The Model Button</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "def submit_button_backpropagation():\n",
    "    layers_neurons = numOf_neurons_text.get().split()\n",
    "    layers_neurons = [int(val) for val in layers_neurons]\n",
    "    main(int(numOf_hidden_layers_text.get()), layers_neurons, activation_fn_var.get(), float(learning_rate_text.get()),\n",
    "         int(epochs_text.get()), int(bias_checkbox.get()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "#Button\n",
    "train_model_button = Button(input_window, text='Train backpropagation', width=17, command=submit_button_backpropagation)\n",
    "train_model_button.place(x=190, y=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "epoch: 0\n",
      "sum square error: 120.0\n",
      "epoch: 1\n",
      "sum square error: 120.0\n",
      "epoch: 2\n",
      "sum square error: 118.0\n",
      "epoch: 3\n",
      "sum square error: 110.0\n",
      "epoch: 4\n",
      "sum square error: 110.0\n",
      "epoch: 5\n",
      "sum square error: 110.0\n",
      "epoch: 6\n",
      "sum square error: 110.0\n",
      "epoch: 7\n",
      "sum square error: 110.0\n",
      "epoch: 8\n",
      "sum square error: 110.0\n",
      "epoch: 9\n",
      "sum square error: 110.0\n",
      "epoch: 10\n",
      "sum square error: 110.0\n",
      "epoch: 11\n",
      "sum square error: 110.0\n",
      "epoch: 12\n",
      "sum square error: 110.0\n",
      "epoch: 13\n",
      "sum square error: 110.0\n",
      "epoch: 14\n",
      "sum square error: 110.0\n",
      "epoch: 15\n",
      "sum square error: 110.0\n",
      "epoch: 16\n",
      "sum square error: 110.0\n",
      "epoch: 17\n",
      "sum square error: 110.0\n",
      "epoch: 18\n",
      "sum square error: 110.0\n",
      "epoch: 19\n",
      "sum square error: 110.0\n",
      "epoch: 20\n",
      "sum square error: 110.0\n",
      "epoch: 21\n",
      "sum square error: 110.0\n",
      "epoch: 22\n",
      "sum square error: 110.0\n",
      "epoch: 23\n",
      "sum square error: 110.0\n",
      "epoch: 24\n",
      "sum square error: 110.0\n",
      "epoch: 25\n",
      "sum square error: 110.0\n",
      "epoch: 26\n",
      "sum square error: 110.0\n",
      "epoch: 27\n",
      "sum square error: 110.0\n",
      "epoch: 28\n",
      "sum square error: 110.0\n",
      "epoch: 29\n",
      "sum square error: 110.0\n",
      "epoch: 30\n",
      "sum square error: 110.0\n",
      "epoch: 31\n",
      "sum square error: 110.0\n",
      "epoch: 32\n",
      "sum square error: 110.0\n",
      "epoch: 33\n",
      "sum square error: 110.0\n",
      "epoch: 34\n",
      "sum square error: 110.0\n",
      "epoch: 35\n",
      "sum square error: 110.0\n",
      "epoch: 36\n",
      "sum square error: 110.0\n",
      "epoch: 37\n",
      "sum square error: 110.0\n",
      "epoch: 38\n",
      "sum square error: 110.0\n",
      "epoch: 39\n",
      "sum square error: 110.0\n",
      "epoch: 40\n",
      "sum square error: 110.0\n",
      "epoch: 41\n",
      "sum square error: 110.0\n",
      "epoch: 42\n",
      "sum square error: 110.0\n",
      "epoch: 43\n",
      "sum square error: 110.0\n",
      "epoch: 44\n",
      "sum square error: 110.0\n",
      "epoch: 45\n",
      "sum square error: 110.0\n",
      "epoch: 46\n",
      "sum square error: 110.0\n",
      "epoch: 47\n",
      "sum square error: 110.0\n",
      "epoch: 48\n",
      "sum square error: 110.0\n",
      "epoch: 49\n",
      "sum square error: 110.0\n",
      "epoch: 50\n",
      "sum square error: 110.0\n",
      "epoch: 51\n",
      "sum square error: 110.0\n",
      "epoch: 52\n",
      "sum square error: 110.0\n",
      "epoch: 53\n",
      "sum square error: 110.0\n",
      "epoch: 54\n",
      "sum square error: 110.0\n",
      "epoch: 55\n",
      "sum square error: 110.0\n",
      "epoch: 56\n",
      "sum square error: 110.0\n",
      "epoch: 57\n",
      "sum square error: 110.0\n",
      "epoch: 58\n",
      "sum square error: 110.0\n",
      "epoch: 59\n",
      "sum square error: 110.0\n",
      "epoch: 60\n",
      "sum square error: 110.0\n",
      "epoch: 61\n",
      "sum square error: 104.0\n",
      "epoch: 62\n",
      "sum square error: 110.0\n",
      "epoch: 63\n",
      "sum square error: 110.0\n",
      "epoch: 64\n",
      "sum square error: 110.0\n",
      "epoch: 65\n",
      "sum square error: 110.0\n",
      "epoch: 66\n",
      "sum square error: 110.0\n",
      "epoch: 67\n",
      "sum square error: 110.0\n",
      "epoch: 68\n",
      "sum square error: 110.0\n",
      "epoch: 69\n",
      "sum square error: 110.0\n",
      "epoch: 70\n",
      "sum square error: 110.0\n",
      "epoch: 71\n",
      "sum square error: 110.0\n",
      "epoch: 72\n",
      "sum square error: 110.0\n",
      "epoch: 73\n",
      "sum square error: 110.0\n",
      "epoch: 74\n",
      "sum square error: 110.0\n",
      "epoch: 75\n",
      "sum square error: 110.0\n",
      "epoch: 76\n",
      "sum square error: 110.0\n",
      "epoch: 77\n",
      "sum square error: 110.0\n",
      "epoch: 78\n",
      "sum square error: 110.0\n",
      "epoch: 79\n",
      "sum square error: 110.0\n",
      "epoch: 80\n",
      "sum square error: 110.0\n",
      "epoch: 81\n",
      "sum square error: 110.0\n",
      "epoch: 82\n",
      "sum square error: 110.0\n",
      "epoch: 83\n",
      "sum square error: 110.0\n",
      "epoch: 84\n",
      "sum square error: 110.0\n",
      "epoch: 85\n",
      "sum square error: 110.0\n",
      "epoch: 86\n",
      "sum square error: 110.0\n",
      "epoch: 87\n",
      "sum square error: 110.0\n",
      "epoch: 88\n",
      "sum square error: 110.0\n",
      "epoch: 89\n",
      "sum square error: 110.0\n",
      "epoch: 90\n",
      "sum square error: 110.0\n",
      "epoch: 91\n",
      "sum square error: 110.0\n",
      "epoch: 92\n",
      "sum square error: 110.0\n",
      "epoch: 93\n",
      "sum square error: 110.0\n",
      "epoch: 94\n",
      "sum square error: 110.0\n",
      "epoch: 95\n",
      "sum square error: 110.0\n",
      "epoch: 96\n",
      "sum square error: 110.0\n",
      "epoch: 97\n",
      "sum square error: 110.0\n",
      "epoch: 98\n",
      "sum square error: 110.0\n",
      "epoch: 99\n",
      "sum square error: 110.0\n",
      "epoch: 100\n",
      "sum square error: 110.0\n",
      "epoch: 101\n",
      "sum square error: 110.0\n",
      "epoch: 102\n",
      "sum square error: 110.0\n",
      "epoch: 103\n",
      "sum square error: 110.0\n",
      "epoch: 104\n",
      "sum square error: 110.0\n",
      "epoch: 105\n",
      "sum square error: 110.0\n",
      "epoch: 106\n",
      "sum square error: 110.0\n",
      "epoch: 107\n",
      "sum square error: 110.0\n",
      "epoch: 108\n",
      "sum square error: 110.0\n",
      "epoch: 109\n",
      "sum square error: 110.0\n",
      "epoch: 110\n",
      "sum square error: 110.0\n",
      "epoch: 111\n",
      "sum square error: 110.0\n",
      "epoch: 112\n",
      "sum square error: 110.0\n",
      "epoch: 113\n",
      "sum square error: 110.0\n",
      "epoch: 114\n",
      "sum square error: 110.0\n",
      "epoch: 115\n",
      "sum square error: 110.0\n",
      "epoch: 116\n",
      "sum square error: 110.0\n",
      "epoch: 117\n",
      "sum square error: 110.0\n",
      "epoch: 118\n",
      "sum square error: 110.0\n",
      "epoch: 119\n",
      "sum square error: 110.0\n",
      "epoch: 120\n",
      "sum square error: 110.0\n",
      "epoch: 121\n",
      "sum square error: 110.0\n",
      "epoch: 122\n",
      "sum square error: 110.0\n",
      "epoch: 123\n",
      "sum square error: 110.0\n",
      "epoch: 124\n",
      "sum square error: 110.0\n",
      "epoch: 125\n",
      "sum square error: 110.0\n",
      "epoch: 126\n",
      "sum square error: 110.0\n",
      "epoch: 127\n",
      "sum square error: 110.0\n",
      "epoch: 128\n",
      "sum square error: 110.0\n",
      "epoch: 129\n",
      "sum square error: 110.0\n",
      "epoch: 130\n",
      "sum square error: 110.0\n",
      "epoch: 131\n",
      "sum square error: 110.0\n",
      "epoch: 132\n",
      "sum square error: 110.0\n",
      "epoch: 133\n",
      "sum square error: 110.0\n",
      "epoch: 134\n",
      "sum square error: 110.0\n",
      "epoch: 135\n",
      "sum square error: 110.0\n",
      "epoch: 136\n",
      "sum square error: 110.0\n",
      "epoch: 137\n",
      "sum square error: 110.0\n",
      "epoch: 138\n",
      "sum square error: 110.0\n",
      "epoch: 139\n",
      "sum square error: 110.0\n",
      "epoch: 140\n",
      "sum square error: 110.0\n",
      "epoch: 141\n",
      "sum square error: 110.0\n",
      "epoch: 142\n",
      "sum square error: 110.0\n",
      "epoch: 143\n",
      "sum square error: 110.0\n",
      "epoch: 144\n",
      "sum square error: 110.0\n",
      "epoch: 145\n",
      "sum square error: 110.0\n",
      "epoch: 146\n",
      "sum square error: 110.0\n",
      "epoch: 147\n",
      "sum square error: 110.0\n",
      "epoch: 148\n",
      "sum square error: 110.0\n",
      "epoch: 149\n",
      "sum square error: 110.0\n",
      "epoch: 150\n",
      "sum square error: 110.0\n",
      "epoch: 151\n",
      "sum square error: 110.0\n",
      "epoch: 152\n",
      "sum square error: 110.0\n",
      "epoch: 153\n",
      "sum square error: 110.0\n",
      "epoch: 154\n",
      "sum square error: 110.0\n",
      "epoch: 155\n",
      "sum square error: 110.0\n",
      "epoch: 156\n",
      "sum square error: 110.0\n",
      "epoch: 157\n",
      "sum square error: 110.0\n",
      "epoch: 158\n",
      "sum square error: 110.0\n",
      "epoch: 159\n",
      "sum square error: 110.0\n",
      "epoch: 160\n",
      "sum square error: 110.0\n",
      "epoch: 161\n",
      "sum square error: 110.0\n",
      "epoch: 162\n",
      "sum square error: 110.0\n",
      "epoch: 163\n",
      "sum square error: 110.0\n",
      "epoch: 164\n",
      "sum square error: 110.0\n",
      "epoch: 165\n",
      "sum square error: 110.0\n",
      "epoch: 166\n",
      "sum square error: 110.0\n",
      "epoch: 167\n",
      "sum square error: 110.0\n",
      "epoch: 168\n",
      "sum square error: 110.0\n",
      "epoch: 169\n",
      "sum square error: 108.0\n",
      "epoch: 170\n",
      "sum square error: 110.0\n",
      "epoch: 171\n",
      "sum square error: 110.0\n",
      "epoch: 172\n",
      "sum square error: 110.0\n",
      "epoch: 173\n",
      "sum square error: 110.0\n",
      "epoch: 174\n",
      "sum square error: 110.0\n",
      "epoch: 175\n",
      "sum square error: 110.0\n",
      "epoch: 176\n",
      "sum square error: 110.0\n",
      "epoch: 177\n",
      "sum square error: 110.0\n",
      "epoch: 178\n",
      "sum square error: 110.0\n",
      "epoch: 179\n",
      "sum square error: 110.0\n",
      "epoch: 180\n",
      "sum square error: 110.0\n",
      "epoch: 181\n",
      "sum square error: 110.0\n",
      "epoch: 182\n",
      "sum square error: 110.0\n",
      "epoch: 183\n",
      "sum square error: 110.0\n",
      "epoch: 184\n",
      "sum square error: 110.0\n",
      "epoch: 185\n",
      "sum square error: 110.0\n",
      "epoch: 186\n",
      "sum square error: 110.0\n",
      "epoch: 187\n",
      "sum square error: 110.0\n",
      "epoch: 188\n",
      "sum square error: 110.0\n",
      "epoch: 189\n",
      "sum square error: 110.0\n",
      "epoch: 190\n",
      "sum square error: 110.0\n",
      "epoch: 191\n",
      "sum square error: 110.0\n",
      "epoch: 192\n",
      "sum square error: 110.0\n",
      "epoch: 193\n",
      "sum square error: 110.0\n",
      "epoch: 194\n",
      "sum square error: 110.0\n",
      "epoch: 195\n",
      "sum square error: 110.0\n",
      "epoch: 196\n",
      "sum square error: 110.0\n",
      "epoch: 197\n",
      "sum square error: 110.0\n",
      "epoch: 198\n",
      "sum square error: 110.0\n",
      "epoch: 199\n",
      "sum square error: 110.0\n",
      "[[1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1]]\n",
      "Testing accuracy:\n",
      " 33.33333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-348-75233577d4ed>\", line 5, in submit_button_backpropagation\n",
      "    int(epochs_text.get()), int(bias_checkbox.get()))\n",
      "  File \"<ipython-input-339-3997b81b76ea>\", line 21, in main\n",
      "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_prediction_test))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 253, in confusion_matrix\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 81, in _check_targets\n",
      "    \"and {1} targets\".format(type_true, type_pred))\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass-multioutput targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "epoch: 0\n",
      "sum square error: 120.0\n",
      "epoch: 1\n",
      "sum square error: 116.0\n",
      "epoch: 2\n",
      "sum square error: 120.0\n",
      "epoch: 3\n",
      "sum square error: 120.0\n",
      "epoch: 4\n",
      "sum square error: 126.0\n",
      "epoch: 5\n",
      "sum square error: 128.0\n",
      "epoch: 6\n",
      "sum square error: 128.0\n",
      "epoch: 7\n",
      "sum square error: 128.0\n",
      "epoch: 8\n",
      "sum square error: 128.0\n",
      "epoch: 9\n",
      "sum square error: 128.0\n",
      "epoch: 10\n",
      "sum square error: 128.0\n",
      "epoch: 11\n",
      "sum square error: 128.0\n",
      "epoch: 12\n",
      "sum square error: 128.0\n",
      "epoch: 13\n",
      "sum square error: 128.0\n",
      "epoch: 14\n",
      "sum square error: 128.0\n",
      "epoch: 15\n",
      "sum square error: 134.0\n",
      "epoch: 16\n",
      "sum square error: 130.0\n",
      "epoch: 17\n",
      "sum square error: 128.0\n",
      "epoch: 18\n",
      "sum square error: 128.0\n",
      "epoch: 19\n",
      "sum square error: 128.0\n",
      "epoch: 20\n",
      "sum square error: 128.0\n",
      "epoch: 21\n",
      "sum square error: 128.0\n",
      "epoch: 22\n",
      "sum square error: 128.0\n",
      "epoch: 23\n",
      "sum square error: 128.0\n",
      "epoch: 24\n",
      "sum square error: 128.0\n",
      "epoch: 25\n",
      "sum square error: 128.0\n",
      "epoch: 26\n",
      "sum square error: 128.0\n",
      "epoch: 27\n",
      "sum square error: 128.0\n",
      "epoch: 28\n",
      "sum square error: 128.0\n",
      "epoch: 29\n",
      "sum square error: 128.0\n",
      "epoch: 30\n",
      "sum square error: 128.0\n",
      "epoch: 31\n",
      "sum square error: 128.0\n",
      "epoch: 32\n",
      "sum square error: 128.0\n",
      "epoch: 33\n",
      "sum square error: 128.0\n",
      "epoch: 34\n",
      "sum square error: 128.0\n",
      "epoch: 35\n",
      "sum square error: 128.0\n",
      "epoch: 36\n",
      "sum square error: 128.0\n",
      "epoch: 37\n",
      "sum square error: 128.0\n",
      "epoch: 38\n",
      "sum square error: 128.0\n",
      "epoch: 39\n",
      "sum square error: 134.0\n",
      "epoch: 40\n",
      "sum square error: 150.0\n",
      "epoch: 41\n",
      "sum square error: 138.0\n",
      "epoch: 42\n",
      "sum square error: 130.0\n",
      "epoch: 43\n",
      "sum square error: 130.0\n",
      "epoch: 44\n",
      "sum square error: 130.0\n",
      "epoch: 45\n",
      "sum square error: 130.0\n",
      "epoch: 46\n",
      "sum square error: 130.0\n",
      "epoch: 47\n",
      "sum square error: 128.0\n",
      "epoch: 48\n",
      "sum square error: 128.0\n",
      "epoch: 49\n",
      "sum square error: 128.0\n",
      "epoch: 50\n",
      "sum square error: 118.0\n",
      "epoch: 51\n",
      "sum square error: 112.0\n",
      "epoch: 52\n",
      "sum square error: 122.0\n",
      "epoch: 53\n",
      "sum square error: 128.0\n",
      "epoch: 54\n",
      "sum square error: 128.0\n",
      "epoch: 55\n",
      "sum square error: 132.0\n",
      "epoch: 56\n",
      "sum square error: 148.0\n",
      "epoch: 57\n",
      "sum square error: 150.0\n",
      "epoch: 58\n",
      "sum square error: 130.0\n",
      "epoch: 59\n",
      "sum square error: 128.0\n",
      "epoch: 60\n",
      "sum square error: 128.0\n",
      "epoch: 61\n",
      "sum square error: 128.0\n",
      "epoch: 62\n",
      "sum square error: 128.0\n",
      "epoch: 63\n",
      "sum square error: 128.0\n",
      "epoch: 64\n",
      "sum square error: 128.0\n",
      "epoch: 65\n",
      "sum square error: 128.0\n",
      "epoch: 66\n",
      "sum square error: 128.0\n",
      "epoch: 67\n",
      "sum square error: 128.0\n",
      "epoch: 68\n",
      "sum square error: 128.0\n",
      "epoch: 69\n",
      "sum square error: 128.0\n",
      "epoch: 70\n",
      "sum square error: 128.0\n",
      "epoch: 71\n",
      "sum square error: 128.0\n",
      "epoch: 72\n",
      "sum square error: 128.0\n",
      "epoch: 73\n",
      "sum square error: 128.0\n",
      "epoch: 74\n",
      "sum square error: 128.0\n",
      "epoch: 75\n",
      "sum square error: 128.0\n",
      "epoch: 76\n",
      "sum square error: 128.0\n",
      "epoch: 77\n",
      "sum square error: 128.0\n",
      "epoch: 78\n",
      "sum square error: 128.0\n",
      "epoch: 79\n",
      "sum square error: 128.0\n",
      "epoch: 80\n",
      "sum square error: 134.0\n",
      "epoch: 81\n",
      "sum square error: 130.0\n",
      "epoch: 82\n",
      "sum square error: 128.0\n",
      "epoch: 83\n",
      "sum square error: 128.0\n",
      "epoch: 84\n",
      "sum square error: 128.0\n",
      "epoch: 85\n",
      "sum square error: 128.0\n",
      "epoch: 86\n",
      "sum square error: 128.0\n",
      "epoch: 87\n",
      "sum square error: 128.0\n",
      "epoch: 88\n",
      "sum square error: 128.0\n",
      "epoch: 89\n",
      "sum square error: 128.0\n",
      "epoch: 90\n",
      "sum square error: 128.0\n",
      "epoch: 91\n",
      "sum square error: 128.0\n",
      "epoch: 92\n",
      "sum square error: 128.0\n",
      "epoch: 93\n",
      "sum square error: 128.0\n",
      "epoch: 94\n",
      "sum square error: 128.0\n",
      "epoch: 95\n",
      "sum square error: 128.0\n",
      "epoch: 96\n",
      "sum square error: 128.0\n",
      "epoch: 97\n",
      "sum square error: 128.0\n",
      "epoch: 98\n",
      "sum square error: 128.0\n",
      "epoch: 99\n",
      "sum square error: 128.0\n",
      "epoch: 100\n",
      "sum square error: 128.0\n",
      "epoch: 101\n",
      "sum square error: 128.0\n",
      "epoch: 102\n",
      "sum square error: 128.0\n",
      "epoch: 103\n",
      "sum square error: 128.0\n",
      "epoch: 104\n",
      "sum square error: 128.0\n",
      "epoch: 105\n",
      "sum square error: 128.0\n",
      "epoch: 106\n",
      "sum square error: 128.0\n",
      "epoch: 107\n",
      "sum square error: 136.0\n",
      "epoch: 108\n",
      "sum square error: 128.0\n",
      "epoch: 109\n",
      "sum square error: 128.0\n",
      "epoch: 110\n",
      "sum square error: 128.0\n",
      "epoch: 111\n",
      "sum square error: 128.0\n",
      "epoch: 112\n",
      "sum square error: 128.0\n",
      "epoch: 113\n",
      "sum square error: 128.0\n",
      "epoch: 114\n",
      "sum square error: 128.0\n",
      "epoch: 115\n",
      "sum square error: 128.0\n",
      "epoch: 116\n",
      "sum square error: 128.0\n",
      "epoch: 117\n",
      "sum square error: 128.0\n",
      "epoch: 118\n",
      "sum square error: 128.0\n",
      "epoch: 119\n",
      "sum square error: 128.0\n",
      "epoch: 120\n",
      "sum square error: 128.0\n",
      "epoch: 121\n",
      "sum square error: 128.0\n",
      "epoch: 122\n",
      "sum square error: 128.0\n",
      "epoch: 123\n",
      "sum square error: 128.0\n",
      "epoch: 124\n",
      "sum square error: 128.0\n",
      "epoch: 125\n",
      "sum square error: 128.0\n",
      "epoch: 126\n",
      "sum square error: 128.0\n",
      "epoch: 127\n",
      "sum square error: 134.0\n",
      "epoch: 128\n",
      "sum square error: 150.0\n",
      "epoch: 129\n",
      "sum square error: 140.0\n",
      "epoch: 130\n",
      "sum square error: 128.0\n",
      "epoch: 131\n",
      "sum square error: 128.0\n",
      "epoch: 132\n",
      "sum square error: 128.0\n",
      "epoch: 133\n",
      "sum square error: 128.0\n",
      "epoch: 134\n",
      "sum square error: 128.0\n",
      "epoch: 135\n",
      "sum square error: 128.0\n",
      "epoch: 136\n",
      "sum square error: 128.0\n",
      "epoch: 137\n",
      "sum square error: 128.0\n",
      "epoch: 138\n",
      "sum square error: 128.0\n",
      "epoch: 139\n",
      "sum square error: 128.0\n",
      "epoch: 140\n",
      "sum square error: 128.0\n",
      "epoch: 141\n",
      "sum square error: 128.0\n",
      "epoch: 142\n",
      "sum square error: 128.0\n",
      "epoch: 143\n",
      "sum square error: 128.0\n",
      "epoch: 144\n",
      "sum square error: 130.0\n",
      "epoch: 145\n",
      "sum square error: 132.0\n",
      "epoch: 146\n",
      "sum square error: 140.0\n",
      "epoch: 147\n",
      "sum square error: 136.0\n",
      "epoch: 148\n",
      "sum square error: 128.0\n",
      "epoch: 149\n",
      "sum square error: 128.0\n",
      "epoch: 150\n",
      "sum square error: 128.0\n",
      "epoch: 151\n",
      "sum square error: 128.0\n",
      "epoch: 152\n",
      "sum square error: 128.0\n",
      "epoch: 153\n",
      "sum square error: 128.0\n",
      "epoch: 154\n",
      "sum square error: 128.0\n",
      "epoch: 155\n",
      "sum square error: 128.0\n",
      "epoch: 156\n",
      "sum square error: 128.0\n",
      "epoch: 157\n",
      "sum square error: 128.0\n",
      "epoch: 158\n",
      "sum square error: 128.0\n",
      "epoch: 159\n",
      "sum square error: 128.0\n",
      "epoch: 160\n",
      "sum square error: 128.0\n",
      "epoch: 161\n",
      "sum square error: 128.0\n",
      "epoch: 162\n",
      "sum square error: 128.0\n",
      "epoch: 163\n",
      "sum square error: 128.0\n",
      "epoch: 164\n",
      "sum square error: 128.0\n",
      "epoch: 165\n",
      "sum square error: 128.0\n",
      "epoch: 166\n",
      "sum square error: 128.0\n",
      "epoch: 167\n",
      "sum square error: 128.0\n",
      "epoch: 168\n",
      "sum square error: 128.0\n",
      "epoch: 169\n",
      "sum square error: 128.0\n",
      "epoch: 170\n",
      "sum square error: 128.0\n",
      "epoch: 171\n",
      "sum square error: 128.0\n",
      "epoch: 172\n",
      "sum square error: 128.0\n",
      "epoch: 173\n",
      "sum square error: 134.0\n",
      "epoch: 174\n",
      "sum square error: 128.0\n",
      "epoch: 175\n",
      "sum square error: 128.0\n",
      "epoch: 176\n",
      "sum square error: 128.0\n",
      "epoch: 177\n",
      "sum square error: 128.0\n",
      "epoch: 178\n",
      "sum square error: 128.0\n",
      "epoch: 179\n",
      "sum square error: 128.0\n",
      "epoch: 180\n",
      "sum square error: 128.0\n",
      "epoch: 181\n",
      "sum square error: 128.0\n",
      "epoch: 182\n",
      "sum square error: 128.0\n",
      "epoch: 183\n",
      "sum square error: 128.0\n",
      "epoch: 184\n",
      "sum square error: 128.0\n",
      "epoch: 185\n",
      "sum square error: 128.0\n",
      "epoch: 186\n",
      "sum square error: 128.0\n",
      "epoch: 187\n",
      "sum square error: 128.0\n",
      "epoch: 188\n",
      "sum square error: 128.0\n",
      "epoch: 189\n",
      "sum square error: 128.0\n",
      "epoch: 190\n",
      "sum square error: 128.0\n",
      "epoch: 191\n",
      "sum square error: 128.0\n",
      "epoch: 192\n",
      "sum square error: 128.0\n",
      "epoch: 193\n",
      "sum square error: 128.0\n",
      "epoch: 194\n",
      "sum square error: 128.0\n",
      "epoch: 195\n",
      "sum square error: 128.0\n",
      "epoch: 196\n",
      "sum square error: 128.0\n",
      "epoch: 197\n",
      "sum square error: 128.0\n",
      "epoch: 198\n",
      "sum square error: 134.0\n",
      "epoch: 199\n",
      "sum square error: 144.0\n",
      "epoch: 200\n",
      "sum square error: 132.0\n",
      "epoch: 201\n",
      "sum square error: 128.0\n",
      "epoch: 202\n",
      "sum square error: 124.0\n",
      "epoch: 203\n",
      "sum square error: 118.0\n",
      "epoch: 204\n",
      "sum square error: 112.0\n",
      "epoch: 205\n",
      "sum square error: 128.0\n",
      "epoch: 206\n",
      "sum square error: 128.0\n",
      "epoch: 207\n",
      "sum square error: 128.0\n",
      "epoch: 208\n",
      "sum square error: 128.0\n",
      "epoch: 209\n",
      "sum square error: 128.0\n",
      "epoch: 210\n",
      "sum square error: 128.0\n",
      "epoch: 211\n",
      "sum square error: 128.0\n",
      "epoch: 212\n",
      "sum square error: 128.0\n",
      "epoch: 213\n",
      "sum square error: 128.0\n",
      "epoch: 214\n",
      "sum square error: 128.0\n",
      "epoch: 215\n",
      "sum square error: 134.0\n",
      "epoch: 216\n",
      "sum square error: 150.0\n",
      "epoch: 217\n",
      "sum square error: 136.0\n",
      "epoch: 218\n",
      "sum square error: 128.0\n",
      "epoch: 219\n",
      "sum square error: 128.0\n",
      "epoch: 220\n",
      "sum square error: 128.0\n",
      "epoch: 221\n",
      "sum square error: 128.0\n",
      "epoch: 222\n",
      "sum square error: 128.0\n",
      "epoch: 223\n",
      "sum square error: 128.0\n",
      "epoch: 224\n",
      "sum square error: 128.0\n",
      "epoch: 225\n",
      "sum square error: 128.0\n",
      "epoch: 226\n",
      "sum square error: 128.0\n",
      "epoch: 227\n",
      "sum square error: 128.0\n",
      "epoch: 228\n",
      "sum square error: 128.0\n",
      "epoch: 229\n",
      "sum square error: 128.0\n",
      "epoch: 230\n",
      "sum square error: 128.0\n",
      "epoch: 231\n",
      "sum square error: 128.0\n",
      "epoch: 232\n",
      "sum square error: 128.0\n",
      "epoch: 233\n",
      "sum square error: 128.0\n",
      "epoch: 234\n",
      "sum square error: 128.0\n",
      "epoch: 235\n",
      "sum square error: 128.0\n",
      "epoch: 236\n",
      "sum square error: 128.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 237\n",
      "sum square error: 128.0\n",
      "epoch: 238\n",
      "sum square error: 132.0\n",
      "epoch: 239\n",
      "sum square error: 128.0\n",
      "epoch: 240\n",
      "sum square error: 128.0\n",
      "epoch: 241\n",
      "sum square error: 128.0\n",
      "epoch: 242\n",
      "sum square error: 128.0\n",
      "epoch: 243\n",
      "sum square error: 128.0\n",
      "epoch: 244\n",
      "sum square error: 128.0\n",
      "epoch: 245\n",
      "sum square error: 128.0\n",
      "epoch: 246\n",
      "sum square error: 128.0\n",
      "epoch: 247\n",
      "sum square error: 128.0\n",
      "epoch: 248\n",
      "sum square error: 128.0\n",
      "epoch: 249\n",
      "sum square error: 128.0\n",
      "epoch: 250\n",
      "sum square error: 128.0\n",
      "epoch: 251\n",
      "sum square error: 128.0\n",
      "epoch: 252\n",
      "sum square error: 128.0\n",
      "epoch: 253\n",
      "sum square error: 128.0\n",
      "epoch: 254\n",
      "sum square error: 128.0\n",
      "epoch: 255\n",
      "sum square error: 128.0\n",
      "epoch: 256\n",
      "sum square error: 128.0\n",
      "epoch: 257\n",
      "sum square error: 128.0\n",
      "epoch: 258\n",
      "sum square error: 128.0\n",
      "epoch: 259\n",
      "sum square error: 128.0\n",
      "epoch: 260\n",
      "sum square error: 128.0\n",
      "epoch: 261\n",
      "sum square error: 128.0\n",
      "epoch: 262\n",
      "sum square error: 128.0\n",
      "epoch: 263\n",
      "sum square error: 128.0\n",
      "epoch: 264\n",
      "sum square error: 128.0\n",
      "epoch: 265\n",
      "sum square error: 134.0\n",
      "epoch: 266\n",
      "sum square error: 128.0\n",
      "epoch: 267\n",
      "sum square error: 128.0\n",
      "epoch: 268\n",
      "sum square error: 128.0\n",
      "epoch: 269\n",
      "sum square error: 128.0\n",
      "epoch: 270\n",
      "sum square error: 128.0\n",
      "epoch: 271\n",
      "sum square error: 128.0\n",
      "epoch: 272\n",
      "sum square error: 128.0\n",
      "epoch: 273\n",
      "sum square error: 128.0\n",
      "epoch: 274\n",
      "sum square error: 128.0\n",
      "epoch: 275\n",
      "sum square error: 128.0\n",
      "epoch: 276\n",
      "sum square error: 128.0\n",
      "epoch: 277\n",
      "sum square error: 128.0\n",
      "epoch: 278\n",
      "sum square error: 128.0\n",
      "epoch: 279\n",
      "sum square error: 128.0\n",
      "epoch: 280\n",
      "sum square error: 128.0\n",
      "epoch: 281\n",
      "sum square error: 128.0\n",
      "epoch: 282\n",
      "sum square error: 128.0\n",
      "epoch: 283\n",
      "sum square error: 128.0\n",
      "epoch: 284\n",
      "sum square error: 128.0\n",
      "epoch: 285\n",
      "sum square error: 128.0\n",
      "epoch: 286\n",
      "sum square error: 134.0\n",
      "epoch: 287\n",
      "sum square error: 150.0\n",
      "epoch: 288\n",
      "sum square error: 140.0\n",
      "epoch: 289\n",
      "sum square error: 128.0\n",
      "epoch: 290\n",
      "sum square error: 128.0\n",
      "epoch: 291\n",
      "sum square error: 128.0\n",
      "epoch: 292\n",
      "sum square error: 128.0\n",
      "epoch: 293\n",
      "sum square error: 128.0\n",
      "epoch: 294\n",
      "sum square error: 128.0\n",
      "epoch: 295\n",
      "sum square error: 128.0\n",
      "epoch: 296\n",
      "sum square error: 128.0\n",
      "epoch: 297\n",
      "sum square error: 130.0\n",
      "epoch: 298\n",
      "sum square error: 130.0\n",
      "epoch: 299\n",
      "sum square error: 130.0\n",
      "epoch: 300\n",
      "sum square error: 130.0\n",
      "epoch: 301\n",
      "sum square error: 130.0\n",
      "epoch: 302\n",
      "sum square error: 128.0\n",
      "epoch: 303\n",
      "sum square error: 128.0\n",
      "epoch: 304\n",
      "sum square error: 144.0\n",
      "epoch: 305\n",
      "sum square error: 150.0\n",
      "epoch: 306\n",
      "sum square error: 130.0\n",
      "epoch: 307\n",
      "sum square error: 128.0\n",
      "epoch: 308\n",
      "sum square error: 128.0\n",
      "epoch: 309\n",
      "sum square error: 128.0\n",
      "epoch: 310\n",
      "sum square error: 128.0\n",
      "epoch: 311\n",
      "sum square error: 128.0\n",
      "epoch: 312\n",
      "sum square error: 128.0\n",
      "epoch: 313\n",
      "sum square error: 128.0\n",
      "epoch: 314\n",
      "sum square error: 128.0\n",
      "epoch: 315\n",
      "sum square error: 128.0\n",
      "epoch: 316\n",
      "sum square error: 128.0\n",
      "epoch: 317\n",
      "sum square error: 128.0\n",
      "epoch: 318\n",
      "sum square error: 128.0\n",
      "epoch: 319\n",
      "sum square error: 128.0\n",
      "epoch: 320\n",
      "sum square error: 128.0\n",
      "epoch: 321\n",
      "sum square error: 128.0\n",
      "epoch: 322\n",
      "sum square error: 128.0\n",
      "epoch: 323\n",
      "sum square error: 128.0\n",
      "epoch: 324\n",
      "sum square error: 128.0\n",
      "epoch: 325\n",
      "sum square error: 128.0\n",
      "epoch: 326\n",
      "sum square error: 128.0\n",
      "epoch: 327\n",
      "sum square error: 128.0\n",
      "epoch: 328\n",
      "sum square error: 128.0\n",
      "epoch: 329\n",
      "sum square error: 128.0\n",
      "epoch: 330\n",
      "sum square error: 136.0\n",
      "epoch: 331\n",
      "sum square error: 128.0\n",
      "epoch: 332\n",
      "sum square error: 128.0\n",
      "epoch: 333\n",
      "sum square error: 128.0\n",
      "epoch: 334\n",
      "sum square error: 128.0\n",
      "epoch: 335\n",
      "sum square error: 128.0\n",
      "epoch: 336\n",
      "sum square error: 128.0\n",
      "epoch: 337\n",
      "sum square error: 128.0\n",
      "epoch: 338\n",
      "sum square error: 128.0\n",
      "epoch: 339\n",
      "sum square error: 128.0\n",
      "epoch: 340\n",
      "sum square error: 128.0\n",
      "epoch: 341\n",
      "sum square error: 128.0\n",
      "epoch: 342\n",
      "sum square error: 128.0\n",
      "epoch: 343\n",
      "sum square error: 128.0\n",
      "epoch: 344\n",
      "sum square error: 128.0\n",
      "epoch: 345\n",
      "sum square error: 128.0\n",
      "epoch: 346\n",
      "sum square error: 128.0\n",
      "epoch: 347\n",
      "sum square error: 128.0\n",
      "epoch: 348\n",
      "sum square error: 128.0\n",
      "epoch: 349\n",
      "sum square error: 128.0\n",
      "epoch: 350\n",
      "sum square error: 128.0\n",
      "epoch: 351\n",
      "sum square error: 128.0\n",
      "epoch: 352\n",
      "sum square error: 128.0\n",
      "epoch: 353\n",
      "sum square error: 128.0\n",
      "epoch: 354\n",
      "sum square error: 128.0\n",
      "epoch: 355\n",
      "sum square error: 128.0\n",
      "epoch: 356\n",
      "sum square error: 132.0\n",
      "epoch: 357\n",
      "sum square error: 120.0\n",
      "epoch: 358\n",
      "sum square error: 108.0\n",
      "epoch: 359\n",
      "sum square error: 122.0\n",
      "epoch: 360\n",
      "sum square error: 128.0\n",
      "epoch: 361\n",
      "sum square error: 128.0\n",
      "epoch: 362\n",
      "sum square error: 128.0\n",
      "epoch: 363\n",
      "sum square error: 128.0\n",
      "epoch: 364\n",
      "sum square error: 128.0\n",
      "epoch: 365\n",
      "sum square error: 128.0\n",
      "epoch: 366\n",
      "sum square error: 128.0\n",
      "epoch: 367\n",
      "sum square error: 128.0\n",
      "epoch: 368\n",
      "sum square error: 128.0\n",
      "epoch: 369\n",
      "sum square error: 128.0\n",
      "epoch: 370\n",
      "sum square error: 128.0\n",
      "epoch: 371\n",
      "sum square error: 128.0\n",
      "epoch: 372\n",
      "sum square error: 128.0\n",
      "epoch: 373\n",
      "sum square error: 134.0\n",
      "epoch: 374\n",
      "sum square error: 150.0\n",
      "epoch: 375\n",
      "sum square error: 144.0\n",
      "epoch: 376\n",
      "sum square error: 128.0\n",
      "epoch: 377\n",
      "sum square error: 128.0\n",
      "epoch: 378\n",
      "sum square error: 128.0\n",
      "epoch: 379\n",
      "sum square error: 128.0\n",
      "epoch: 380\n",
      "sum square error: 128.0\n",
      "epoch: 381\n",
      "sum square error: 128.0\n",
      "epoch: 382\n",
      "sum square error: 128.0\n",
      "epoch: 383\n",
      "sum square error: 128.0\n",
      "epoch: 384\n",
      "sum square error: 128.0\n",
      "epoch: 385\n",
      "sum square error: 128.0\n",
      "epoch: 386\n",
      "sum square error: 128.0\n",
      "epoch: 387\n",
      "sum square error: 128.0\n",
      "epoch: 388\n",
      "sum square error: 128.0\n",
      "epoch: 389\n",
      "sum square error: 128.0\n",
      "epoch: 390\n",
      "sum square error: 128.0\n",
      "epoch: 391\n",
      "sum square error: 128.0\n",
      "epoch: 392\n",
      "sum square error: 128.0\n",
      "epoch: 393\n",
      "sum square error: 128.0\n",
      "epoch: 394\n",
      "sum square error: 128.0\n",
      "epoch: 395\n",
      "sum square error: 136.0\n",
      "epoch: 396\n",
      "sum square error: 128.0\n",
      "epoch: 397\n",
      "sum square error: 128.0\n",
      "epoch: 398\n",
      "sum square error: 128.0\n",
      "epoch: 399\n",
      "sum square error: 128.0\n",
      "[[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0]]\n",
      "Testing accuracy:\n",
      " 33.33333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-348-75233577d4ed>\", line 5, in submit_button_backpropagation\n",
      "    int(epochs_text.get()), int(bias_checkbox.get()))\n",
      "  File \"<ipython-input-339-3997b81b76ea>\", line 21, in main\n",
      "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_prediction_test))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 253, in confusion_matrix\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 81, in _check_targets\n",
      "    \"and {1} targets\".format(type_true, type_pred))\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass-multioutput targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "epoch: 0\n",
      "sum square error: 120.0\n",
      "epoch: 1\n",
      "sum square error: 120.0\n",
      "epoch: 2\n",
      "sum square error: 120.0\n",
      "epoch: 3\n",
      "sum square error: 120.0\n",
      "epoch: 4\n",
      "sum square error: 120.0\n",
      "epoch: 5\n",
      "sum square error: 120.0\n",
      "epoch: 6\n",
      "sum square error: 120.0\n",
      "epoch: 7\n",
      "sum square error: 120.0\n",
      "epoch: 8\n",
      "sum square error: 120.0\n",
      "epoch: 9\n",
      "sum square error: 120.0\n",
      "epoch: 10\n",
      "sum square error: 120.0\n",
      "epoch: 11\n",
      "sum square error: 120.0\n",
      "epoch: 12\n",
      "sum square error: 120.0\n",
      "epoch: 13\n",
      "sum square error: 120.0\n",
      "epoch: 14\n",
      "sum square error: 120.0\n",
      "epoch: 15\n",
      "sum square error: 120.0\n",
      "epoch: 16\n",
      "sum square error: 120.0\n",
      "epoch: 17\n",
      "sum square error: 120.0\n",
      "epoch: 18\n",
      "sum square error: 120.0\n",
      "epoch: 19\n",
      "sum square error: 120.0\n",
      "epoch: 20\n",
      "sum square error: 120.0\n",
      "epoch: 21\n",
      "sum square error: 120.0\n",
      "epoch: 22\n",
      "sum square error: 120.0\n",
      "epoch: 23\n",
      "sum square error: 120.0\n",
      "epoch: 24\n",
      "sum square error: 132.0\n",
      "epoch: 25\n",
      "sum square error: 138.0\n",
      "epoch: 26\n",
      "sum square error: 138.0\n",
      "epoch: 27\n",
      "sum square error: 138.0\n",
      "epoch: 28\n",
      "sum square error: 136.0\n",
      "epoch: 29\n",
      "sum square error: 128.0\n",
      "epoch: 30\n",
      "sum square error: 128.0\n",
      "epoch: 31\n",
      "sum square error: 120.0\n",
      "epoch: 32\n",
      "sum square error: 124.0\n",
      "epoch: 33\n",
      "sum square error: 128.0\n",
      "epoch: 34\n",
      "sum square error: 144.0\n",
      "epoch: 35\n",
      "sum square error: 140.0\n",
      "epoch: 36\n",
      "sum square error: 144.0\n",
      "epoch: 37\n",
      "sum square error: 148.0\n",
      "epoch: 38\n",
      "sum square error: 146.0\n",
      "epoch: 39\n",
      "sum square error: 144.0\n",
      "epoch: 40\n",
      "sum square error: 144.0\n",
      "epoch: 41\n",
      "sum square error: 144.0\n",
      "epoch: 42\n",
      "sum square error: 142.0\n",
      "epoch: 43\n",
      "sum square error: 142.0\n",
      "epoch: 44\n",
      "sum square error: 140.0\n",
      "epoch: 45\n",
      "sum square error: 140.0\n",
      "epoch: 46\n",
      "sum square error: 140.0\n",
      "epoch: 47\n",
      "sum square error: 142.0\n",
      "epoch: 48\n",
      "sum square error: 142.0\n",
      "epoch: 49\n",
      "sum square error: 140.0\n",
      "epoch: 50\n",
      "sum square error: 144.0\n",
      "epoch: 51\n",
      "sum square error: 136.0\n",
      "epoch: 52\n",
      "sum square error: 132.0\n",
      "epoch: 53\n",
      "sum square error: 136.0\n",
      "epoch: 54\n",
      "sum square error: 134.0\n",
      "epoch: 55\n",
      "sum square error: 138.0\n",
      "epoch: 56\n",
      "sum square error: 138.0\n",
      "epoch: 57\n",
      "sum square error: 138.0\n",
      "epoch: 58\n",
      "sum square error: 138.0\n",
      "epoch: 59\n",
      "sum square error: 138.0\n",
      "epoch: 60\n",
      "sum square error: 138.0\n",
      "epoch: 61\n",
      "sum square error: 138.0\n",
      "epoch: 62\n",
      "sum square error: 138.0\n",
      "epoch: 63\n",
      "sum square error: 138.0\n",
      "epoch: 64\n",
      "sum square error: 138.0\n",
      "epoch: 65\n",
      "sum square error: 138.0\n",
      "epoch: 66\n",
      "sum square error: 140.0\n",
      "epoch: 67\n",
      "sum square error: 140.0\n",
      "epoch: 68\n",
      "sum square error: 144.0\n",
      "epoch: 69\n",
      "sum square error: 144.0\n",
      "epoch: 70\n",
      "sum square error: 148.0\n",
      "epoch: 71\n",
      "sum square error: 148.0\n",
      "epoch: 72\n",
      "sum square error: 150.0\n",
      "epoch: 73\n",
      "sum square error: 150.0\n",
      "epoch: 74\n",
      "sum square error: 144.0\n",
      "epoch: 75\n",
      "sum square error: 142.0\n",
      "epoch: 76\n",
      "sum square error: 142.0\n",
      "epoch: 77\n",
      "sum square error: 138.0\n",
      "epoch: 78\n",
      "sum square error: 138.0\n",
      "epoch: 79\n",
      "sum square error: 138.0\n",
      "epoch: 80\n",
      "sum square error: 138.0\n",
      "epoch: 81\n",
      "sum square error: 138.0\n",
      "epoch: 82\n",
      "sum square error: 138.0\n",
      "epoch: 83\n",
      "sum square error: 138.0\n",
      "epoch: 84\n",
      "sum square error: 138.0\n",
      "epoch: 85\n",
      "sum square error: 138.0\n",
      "epoch: 86\n",
      "sum square error: 138.0\n",
      "epoch: 87\n",
      "sum square error: 138.0\n",
      "epoch: 88\n",
      "sum square error: 138.0\n",
      "epoch: 89\n",
      "sum square error: 138.0\n",
      "epoch: 90\n",
      "sum square error: 138.0\n",
      "epoch: 91\n",
      "sum square error: 138.0\n",
      "epoch: 92\n",
      "sum square error: 138.0\n",
      "epoch: 93\n",
      "sum square error: 140.0\n",
      "epoch: 94\n",
      "sum square error: 144.0\n",
      "epoch: 95\n",
      "sum square error: 142.0\n",
      "epoch: 96\n",
      "sum square error: 140.0\n",
      "epoch: 97\n",
      "sum square error: 146.0\n",
      "epoch: 98\n",
      "sum square error: 146.0\n",
      "epoch: 99\n",
      "sum square error: 144.0\n",
      "[[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 0, 1]]\n",
      "Testing accuracy:\n",
      " 33.33333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-348-75233577d4ed>\", line 5, in submit_button_backpropagation\n",
      "    int(epochs_text.get()), int(bias_checkbox.get()))\n",
      "  File \"<ipython-input-339-3997b81b76ea>\", line 21, in main\n",
      "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_prediction_test))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 253, in confusion_matrix\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 81, in _check_targets\n",
      "    \"and {1} targets\".format(type_true, type_pred))\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass-multioutput targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "epoch: 0\n",
      "sum square error: 120.0\n",
      "epoch: 1\n",
      "sum square error: 120.0\n",
      "epoch: 2\n",
      "sum square error: 120.0\n",
      "epoch: 3\n",
      "sum square error: 120.0\n",
      "epoch: 4\n",
      "sum square error: 120.0\n",
      "epoch: 5\n",
      "sum square error: 120.0\n",
      "epoch: 6\n",
      "sum square error: 120.0\n",
      "epoch: 7\n",
      "sum square error: 120.0\n",
      "epoch: 8\n",
      "sum square error: 120.0\n",
      "epoch: 9\n",
      "sum square error: 120.0\n",
      "epoch: 10\n",
      "sum square error: 120.0\n",
      "epoch: 11\n",
      "sum square error: 120.0\n",
      "epoch: 12\n",
      "sum square error: 120.0\n",
      "epoch: 13\n",
      "sum square error: 120.0\n",
      "epoch: 14\n",
      "sum square error: 120.0\n",
      "epoch: 15\n",
      "sum square error: 118.0\n",
      "epoch: 16\n",
      "sum square error: 122.0\n",
      "epoch: 17\n",
      "sum square error: 122.0\n",
      "epoch: 18\n",
      "sum square error: 122.0\n",
      "epoch: 19\n",
      "sum square error: 122.0\n",
      "epoch: 20\n",
      "sum square error: 122.0\n",
      "epoch: 21\n",
      "sum square error: 122.0\n",
      "epoch: 22\n",
      "sum square error: 122.0\n",
      "epoch: 23\n",
      "sum square error: 122.0\n",
      "epoch: 24\n",
      "sum square error: 122.0\n",
      "epoch: 25\n",
      "sum square error: 122.0\n",
      "epoch: 26\n",
      "sum square error: 110.0\n",
      "epoch: 27\n",
      "sum square error: 110.0\n",
      "epoch: 28\n",
      "sum square error: 110.0\n",
      "epoch: 29\n",
      "sum square error: 110.0\n",
      "epoch: 30\n",
      "sum square error: 110.0\n",
      "epoch: 31\n",
      "sum square error: 110.0\n",
      "epoch: 32\n",
      "sum square error: 110.0\n",
      "epoch: 33\n",
      "sum square error: 110.0\n",
      "epoch: 34\n",
      "sum square error: 110.0\n",
      "epoch: 35\n",
      "sum square error: 110.0\n",
      "epoch: 36\n",
      "sum square error: 110.0\n",
      "epoch: 37\n",
      "sum square error: 110.0\n",
      "epoch: 38\n",
      "sum square error: 110.0\n",
      "epoch: 39\n",
      "sum square error: 110.0\n",
      "epoch: 40\n",
      "sum square error: 110.0\n",
      "epoch: 41\n",
      "sum square error: 110.0\n",
      "epoch: 42\n",
      "sum square error: 110.0\n",
      "epoch: 43\n",
      "sum square error: 110.0\n",
      "epoch: 44\n",
      "sum square error: 110.0\n",
      "epoch: 45\n",
      "sum square error: 110.0\n",
      "epoch: 46\n",
      "sum square error: 110.0\n",
      "epoch: 47\n",
      "sum square error: 110.0\n",
      "epoch: 48\n",
      "sum square error: 110.0\n",
      "epoch: 49\n",
      "sum square error: 110.0\n",
      "epoch: 50\n",
      "sum square error: 110.0\n",
      "epoch: 51\n",
      "sum square error: 110.0\n",
      "epoch: 52\n",
      "sum square error: 110.0\n",
      "epoch: 53\n",
      "sum square error: 110.0\n",
      "epoch: 54\n",
      "sum square error: 110.0\n",
      "epoch: 55\n",
      "sum square error: 110.0\n",
      "epoch: 56\n",
      "sum square error: 110.0\n",
      "epoch: 57\n",
      "sum square error: 110.0\n",
      "epoch: 58\n",
      "sum square error: 110.0\n",
      "epoch: 59\n",
      "sum square error: 110.0\n",
      "epoch: 60\n",
      "sum square error: 110.0\n",
      "epoch: 61\n",
      "sum square error: 110.0\n",
      "epoch: 62\n",
      "sum square error: 110.0\n",
      "epoch: 63\n",
      "sum square error: 110.0\n",
      "epoch: 64\n",
      "sum square error: 110.0\n",
      "epoch: 65\n",
      "sum square error: 110.0\n",
      "epoch: 66\n",
      "sum square error: 110.0\n",
      "epoch: 67\n",
      "sum square error: 110.0\n",
      "epoch: 68\n",
      "sum square error: 110.0\n",
      "epoch: 69\n",
      "sum square error: 110.0\n",
      "epoch: 70\n",
      "sum square error: 110.0\n",
      "epoch: 71\n",
      "sum square error: 110.0\n",
      "epoch: 72\n",
      "sum square error: 110.0\n",
      "epoch: 73\n",
      "sum square error: 110.0\n",
      "epoch: 74\n",
      "sum square error: 110.0\n",
      "epoch: 75\n",
      "sum square error: 110.0\n",
      "epoch: 76\n",
      "sum square error: 110.0\n",
      "epoch: 77\n",
      "sum square error: 110.0\n",
      "epoch: 78\n",
      "sum square error: 110.0\n",
      "epoch: 79\n",
      "sum square error: 110.0\n",
      "epoch: 80\n",
      "sum square error: 110.0\n",
      "epoch: 81\n",
      "sum square error: 110.0\n",
      "epoch: 82\n",
      "sum square error: 110.0\n",
      "epoch: 83\n",
      "sum square error: 110.0\n",
      "epoch: 84\n",
      "sum square error: 108.0\n",
      "epoch: 85\n",
      "sum square error: 108.0\n",
      "epoch: 86\n",
      "sum square error: 100.0\n",
      "epoch: 87\n",
      "sum square error: 94.0\n",
      "epoch: 88\n",
      "sum square error: 90.0\n",
      "epoch: 89\n",
      "sum square error: 88.0\n",
      "epoch: 90\n",
      "sum square error: 88.0\n",
      "epoch: 91\n",
      "sum square error: 80.0\n",
      "epoch: 92\n",
      "sum square error: 78.0\n",
      "epoch: 93\n",
      "sum square error: 78.0\n",
      "epoch: 94\n",
      "sum square error: 82.0\n",
      "epoch: 95\n",
      "sum square error: 78.0\n",
      "epoch: 96\n",
      "sum square error: 78.0\n",
      "epoch: 97\n",
      "sum square error: 78.0\n",
      "epoch: 98\n",
      "sum square error: 78.0\n",
      "epoch: 99\n",
      "sum square error: 78.0\n",
      "[[1, 1, 0, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 0, 1, 0], [1, 0, 1, 0]]\n",
      "Testing accuracy:\n",
      " 63.33333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-348-75233577d4ed>\", line 5, in submit_button_backpropagation\n",
      "    int(epochs_text.get()), int(bias_checkbox.get()))\n",
      "  File \"<ipython-input-339-3997b81b76ea>\", line 21, in main\n",
      "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_prediction_test))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 253, in confusion_matrix\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 81, in _check_targets\n",
      "    \"and {1} targets\".format(type_true, type_pred))\n",
      "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass-multioutput targets\n"
     ]
    }
   ],
   "source": [
    "input_window.mainloop() #open window"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "name": "NN Task 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
