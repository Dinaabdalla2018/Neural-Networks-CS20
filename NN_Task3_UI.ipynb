{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfFHnt1nPLti"
   },
   "source": [
    "<h1>Task 3</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZtYDESXlPLtU"
   },
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8Yw_2fiPLta"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjXTNbSqPLte"
   },
   "source": [
    "## Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7T1Bmo6tPLtf"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('IrisData.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid_derivative(x):\n",
    "    f = 1 / (1 + np.exp(-1*x))\n",
    "    return (f * (1 - f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Tangent activation function\n",
    "def tanh_derivative(x):\n",
    "    f = (2/(1 + np.exp(-2*x))-1)\n",
    "    return (1 - (f**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the neural network layers\n",
    "\n",
    "- Each layer consists of an input matrix, a weight matrix and an error list.\n",
    "\n",
    "    - The Input layer, is the x_train or test matrix.\n",
    "\n",
    "    - The output layer, is a (3, 1) matirx.\n",
    "    \n",
    "    - For each of the hidden layers the dimensions are (numOf neurons in this layer, numOf neurons in the previous layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network contains layers in the form of dictionaries, each layer consists of:\n",
    "# numpy array of layer weights.\n",
    "# numpy array of layer inputs.\n",
    "# net value.\n",
    "# gradient value.\n",
    "# All values are randomly intialized.\n",
    "def nn_setup(numOf_hidden_Layers, numOf_neurons):\n",
    "    # adding the number of neurons of the input layer\n",
    "    numOf_neurons.insert(0, data.shape[1])\n",
    "    # a list of dictionaries of numpy arrays, holding the layers weights, inputs, net and gradient value.\n",
    "    network = list()\n",
    "    input_layer   = {'weights':  np.random.rand(numOf_neurons[0]),\n",
    "                     'inputs': np.random.rand(numOf_neurons[0]), \n",
    "                     'net': random(), \n",
    "                     'gradient':random()}\n",
    "    input_layer['weights'] = input_layer['weights'].reshape(input_layer['weights'].shape[0], 1)\n",
    "    input_layer['inputs'] = input_layer['inputs'].reshape(input_layer['inputs'].shape[0], 1)\n",
    "    \n",
    "    hidden_layers = [{'weights': np.random.rand(numOf_neurons[i], numOf_neurons[i - 1]),\n",
    "                      'inputs': np.random.rand(numOf_neurons[i], numOf_neurons[i - 1]), \n",
    "                      'net': random(), \n",
    "                      'gradient': random()} for i in range(1, len(numOf_neurons))]\n",
    "    \n",
    "    output_layer  = {'weights':  np.random.rand(4, numOf_neurons[-1]),\n",
    "                     'inputs': np.random.rand(4, numOf_neurons[-1]), \n",
    "                     'net': random(), \n",
    "                     'gradient': random()}\n",
    "    \n",
    "    network.append(input_layer)\n",
    "    network += hidden_layers\n",
    "    network.append(output_layer)\n",
    "    #print(network)\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Backpropagation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First feed forward function\n",
    "\n",
    "- use vector/matrix multiplication to calculate net value on each layer.\n",
    "    - net  = sum(dot(layer_x, W.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network contains layers in the form of dictionaries, each layer consists of:\n",
    "# numpy array of layer weights.\n",
    "# numpy array of layer inputs.\n",
    "# net value.\n",
    "# gradient value.\n",
    "# All values are randomly intialized.\n",
    "def feed_forward1(network, input_row, activation_fn, use_bias):\n",
    "    # for each layer use vector/matrix multiplication to calculate the net value and update it in the network.\n",
    "    network[0]['inputs'] = input_row.reshape(input_row.shape[0], 1)\n",
    "    network[1]['inputs'] = input_row.reshape(input_row.shape[0], 1)\n",
    "    last_output = []\n",
    "    for i in range(1, len(network)):\n",
    "        if not use_bias:\n",
    "            network[i]['weights'][:][0] = np.zeros(network[i]['weights'].shape[1])\n",
    "        # calculate the product of the current layer's weights and inputs.\n",
    "        neurons_val = np.dot(network[i]['weights'], network[i]['inputs'])\n",
    "        \n",
    "        # apply the activation function on the cur neurons values.\n",
    "        if activation_fn is 'Sigmoid':\n",
    "            neurons_val = [sigmoid_derivative(val) for val in neurons_val]\n",
    "        else:\n",
    "            neurons_val = [tanh_derivative(val) for val in neurons_val]\n",
    "            \n",
    "        # calculate the net value.\n",
    "        network[i]['net'] = neurons_val\n",
    "        \n",
    "        # the next layer input is this layer's output\n",
    "        if i < len(network) - 1:\n",
    "            network[i + 1]['inputs'] = neurons_val\n",
    "        else:\n",
    "            last_output = [1 if max(neurons_val[1:]) is neurons_val[i] else 0 for i in range(1, len(neurons_val))]\n",
    "            last_output.insert(0, 1)\n",
    "            \n",
    "    return network, last_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First feed backward function\n",
    "\n",
    "- use vector/matrix multiplication to calculate gradient value on each layer.\n",
    "    - Output_layer_gradient = (intended_y - predicted_y) * d_activation_fn(net)\n",
    "    - Hidden_layer_gradient_i = (gradient_(i-1) * W_i * d_activation_fn(net_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network contains layers in the form of dictionaries, each layer consists of:\n",
    "# numpy array of layer weights.\n",
    "# numpy array of layer inputs.\n",
    "# net value.\n",
    "# gradient value.\n",
    "# All values are randomly intialized.\n",
    "def feed_backward(network, intended_y, predicted_y, activation_fn):\n",
    "    # for each layer use vector/matrix multiplication to calculate the gradient value and update it in the network.\n",
    "    # calculating gradient for output layer\n",
    "    output_layer = network[len(network) - 1]\n",
    "    output_layer['gradient'] = intended_y - predicted_y\n",
    "    if activation_fn is 'Sigmoid':\n",
    "        deriv = [sigmoid_derivative(val) for val in output_layer['net']]\n",
    "    else:\n",
    "        deriv = [tanh_derivative(val) for val in output_layer['net']]\n",
    "    deriv = np.array(deriv).reshape(-1, 1)\n",
    "    net = np.array(output_layer['net']).reshape(-1, 1)\n",
    "    output_layer['gradient'].flatten()\n",
    "    #np.dot(output_layer['gradient'], deriv)\n",
    "    np.dot(output_layer['gradient'], net)\n",
    "    network[len(network) - 1] = output_layer\n",
    "    \n",
    "    # calculating gradient for hidden layers\n",
    "    previous_gradient = output_layer['gradient']\n",
    "    for i in range(len(network) - 2, 0, -1): # step=-1\n",
    "        layer = network[i]\n",
    "        next_layer = network[i + 1]\n",
    "        layer['gradient'] = np.dot(previous_gradient.T, next_layer['weights'])\n",
    "        if activation_fn is 'Sigmoid':\n",
    "            deriv = [sigmoid_derivative(val) for val in layer['net']]\n",
    "        else:\n",
    "            deriv = [tanh_derivative(val) for val in layer['net']]\n",
    "        deriv = np.array(deriv).reshape(-1, 1)\n",
    "        net = np.array(layer['net']).reshape(-1, 1)\n",
    "        layer['gradient'].flatten()\n",
    "        #np.dot(layer['gradient'], deriv)\n",
    "        np.dot(layer['gradient'], net)\n",
    "        network[i] = layer   \n",
    "        previous_gradient = layer['gradient']\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second feed forward function\n",
    "\n",
    "- use vector/matrix multiplication to Update the weight matrix in each layer.\n",
    "    - W_i = W_i + (learning_rate * gradient_i * x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network contains layers in the form of dictionaries, each layer consists of:\n",
    "# numpy array of layer weights.\n",
    "# numpy array of layer inputs.\n",
    "# net value.\n",
    "# gradient value.\n",
    "# All values are randomly intialized.\n",
    "def feed_forward2(network, learning_rate):\n",
    "     # for each layer use vector/matrix multiplication to calculate the new weights value and update it in the network.\n",
    "    for i in range (1 , len(network)):\n",
    "        layer = network[i]\n",
    "        net = layer['net'] * layer['gradient'] * learning_rate\n",
    "        net = net.reshape(-1, 1)\n",
    "        for neuron_index in range(layer['weights'].shape[0]):\n",
    "            layer['weights'][neuron_index] += net[neuron_index]\n",
    "        network[i] = layer\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation model\n",
    "\n",
    "- For each epoch call:\n",
    "\n",
    "    - Feed forward, calculating the net values for each layer.\n",
    "\n",
    "    - Feed Backward, calculating the gradient values for each layer.\n",
    "\n",
    "    - Feed forward, updating the weights for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(x_train, y_train, network, learning_rate, epochs, use_bias, activation_fn):\n",
    "    # for each epoch:\n",
    "    for i in range(epochs):\n",
    "        for ind in range(x_train.shape[0]):\n",
    "            # call feed_forward1 with the given network, row of data, activation function and use_bias.\n",
    "            network, y_prediction = feed_forward1(network, x_train[ind], activation_fn, use_bias)\n",
    "            # call feed_backward with the returned network, cur row of y_train, cur y_prediction for this row and the activation_fn\n",
    "            network = feed_backward(network, y_train[ind], np.array(y_prediction), activation_fn)\n",
    "            # call feed_forward2 with the returned network and other necessary values\n",
    "            network = feed_forward2(network, learning_rate)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_test, y_test, network, activation_fn, use_bias):\n",
    "    y_prediction = []\n",
    "    for row in x_test:\n",
    "        network, y = feed_forward1(network, row, activation_fn, use_bias)\n",
    "        y_prediction.append(y)\n",
    "    print(y_prediction)\n",
    "    # calculating the accuracy.\n",
    "    comparison = (y_prediction == y_test)\n",
    "    co = 0\n",
    "    for l in comparison:\n",
    "        ans = True\n",
    "        for val in l:\n",
    "            ans &= val\n",
    "        if ans == True:\n",
    "            co += 1\n",
    "    accuracy = (co/y_test.shape[0]) * 100\n",
    "    return y_prediction, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwxUH6jbPLuO"
   },
   "outputs": [],
   "source": [
    "# We will be using all the 4 feauters and 3 classes.\n",
    "# The y column should be on hot encoded, meaning that if the label is c1 \n",
    "    # then it should be represented as follow, 100 and so on.\n",
    "\n",
    "def extract_data():\n",
    "    data_x = data.iloc[:, :4]\n",
    "    x0 = np.ones([150, 1]) # feature 0 for bias\n",
    "    data_x = np.append(x0, data_x, axis=1)\n",
    "    # One hot encoding the ouput column.\n",
    "    values = np.array(data['Class'])\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    data_y = onehot_encoded\n",
    "    data_y = np.append(x0, data_y, axis=1)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.4, shuffle=True, stratify = data_y)\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pl9GMxsjPLuT"
   },
   "outputs": [],
   "source": [
    "def main(numOf_hidden_layers, numOf_nuerons, activation_fn, learning_rate, epochs, use_bias):\n",
    "    # Get the train and test data.\n",
    "    x_train, y_train, x_test, y_test = extract_data()\n",
    "    \n",
    "    # Setup the Neural Network layer.\n",
    "    network = nn_setup(numOf_hidden_layers, numOf_nuerons)\n",
    "    \n",
    "    print(network)\n",
    "    \n",
    "    # Call the backpropagation model and return the learned weights.\n",
    "    network = backpropagation(x_train, y_train, network, learning_rate, epochs, use_bias, activation_fn)\n",
    "\n",
    "    print(network)\n",
    "    \n",
    "    # Test the moddel and return its accuracy, then print it.\n",
    "    y_prediction_test, accuracy_test = test(x_test, y_test, network, activation_fn, use_bias)\n",
    "    print('Testing accuracy:\\n', accuracy_test)\n",
    "    \n",
    "    # print the confusion matrix.\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_prediction_test))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h1>UI</h1>\n",
    "\n",
    "- text box to take the number of desired hidden layers.\n",
    "\n",
    "- text box to take the number of desired neurons in each hidden layer.\n",
    "\n",
    "- combo box to choose the activation function, sigmoid or tanh.\n",
    "\n",
    "- text box to take the desired learning rate.\n",
    "\n",
    "- text box to take the desired number of epochs.\n",
    "\n",
    "- check box for the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "input_window = Tk()\n",
    "input_window.title(\"Neural Networks Task 3\")\n",
    "input_window.geometry(\"500x500\")\n",
    "activation_fns = [\"Sigmoid\", \"Tanh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Number of Hidden Layers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of hidden Layers label\n",
    "numOf_hidden_layers_value = StringVar()\n",
    "numOf_hidden_layers_label = Label(input_window, textvariable = numOf_hidden_layers_value) \n",
    "numOf_hidden_layers_value.set(\"Number of hidden Layers\")\n",
    "numOf_hidden_layers_label.place(x=45, y=100)\n",
    "#Number of hidden Layers text\n",
    "numOf_hidden_layers_text = Entry(input_window)\n",
    "numOf_hidden_layers_text.place(x=190, y=100)\n",
    "numOf_hidden_layers_text.focus_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Number of neurons in each hidden layer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of neurons hidden Layers label\n",
    "numOf_neurons_value = StringVar()\n",
    "numOf_neurons_label = Label(input_window, textvariable = numOf_neurons_value) \n",
    "numOf_neurons_value.set(\"Number of neurons in them\")\n",
    "numOf_neurons_label.place(x=30, y=140)\n",
    "#Number of neurons hidden Layers text\n",
    "numOf_neurons_text = Entry(input_window)\n",
    "numOf_neurons_text.place(x=190, y=140)\n",
    "numOf_neurons_text.focus_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Activation function Dropdown List</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "#Activation fn label\n",
    "activation_fn_value = StringVar()\n",
    "activation_fn_label = Label(input_window, textvariable = activation_fn_value) \n",
    "activation_fn_value.set(\"Activaion function\")\n",
    "activation_fn_label.place(x=80, y=170)\n",
    "#Activation fn list\n",
    "activation_fn_var = StringVar(input_window)\n",
    "activation_fn = OptionMenu(input_window, activation_fn_var, *activation_fns)\n",
    "activation_fn.config(width=12, font=('Helvetica', 10))\n",
    "#activation_fn_var.set('Sigmoid') # set the default option\n",
    "activation_fn.place(x=190, y=170)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Learning Rate</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "#learning rate label\n",
    "learning_rate_value = StringVar()\n",
    "learning_rate_label = Label(input_window, textvariable = learning_rate_value) \n",
    "learning_rate_value.set(\"Learning Rate\")\n",
    "learning_rate_label.place(x=105, y=210)\n",
    "#learning rate text\n",
    "learning_rate_text = Entry(input_window)\n",
    "learning_rate_text.place(x=193, y=210)\n",
    "learning_rate_text.focus_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Epochs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "#Epochs label\n",
    "epochs_label_value = StringVar()\n",
    "epochs_label = Label(input_window, textvariable = epochs_label_value) \n",
    "epochs_label_value.set(\"Epochs\")\n",
    "epochs_label.place(x=140, y=240)\n",
    "#Epochs text\n",
    "epochs_text = Entry(input_window)\n",
    "epochs_text.place(x=193, y=240)\n",
    "epochs_text.focus_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Bias</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "#Bias check box\n",
    "bias_checkbox = IntVar()\n",
    "Checkbutton(input_window, text=\"Bias\", variable=bias_checkbox).place(x=190,y=290)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "source": [
    "<h3>Training The Model Button</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "def submit_button_backpropagation():\n",
    "    layers_neurons = numOf_neurons_text.get().split()\n",
    "    layers_neurons = [int(val) for val in layers_neurons]\n",
    "    main(int(numOf_hidden_layers_text.get()), layers_neurons, activation_fn_var.get(), float(learning_rate_text.get()),\n",
    "         int(epochs_text.get()), int(bias_checkbox.get()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [],
   "source": [
    "#Button\n",
    "train_model_button = Button(input_window, text='Train backpropagation', width=17, command=submit_button_backpropagation)\n",
    "train_model_button.place(x=190, y=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_-ariESPLuV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': array([[0.11876262],\n",
      "       [0.02701475],\n",
      "       [0.41985974],\n",
      "       [0.53088379],\n",
      "       [0.94699367]]), 'inputs': array([[0.14072178],\n",
      "       [0.30272609],\n",
      "       [0.32956244],\n",
      "       [0.10244711],\n",
      "       [0.80673971]]), 'net': 0.2915485209042714, 'gradient': 0.09250016210488632}, {'weights': array([[0.83197294, 0.85250386, 0.75874892, 0.27086847, 0.89948105],\n",
      "       [0.53153975, 0.67890424, 0.83330885, 0.99128863, 0.43000889],\n",
      "       [0.20303106, 0.39891612, 0.32731053, 0.29146927, 0.24133346],\n",
      "       [0.51087705, 0.17338538, 0.14506082, 0.86618465, 0.97314113],\n",
      "       [0.03925007, 0.16949813, 0.54006018, 0.95635197, 0.06731636]]), 'inputs': array([[0.1048068 , 0.8521688 , 0.91715497, 0.42437696, 0.0785714 ],\n",
      "       [0.35911262, 0.79289557, 0.63152992, 0.63947817, 0.98331047],\n",
      "       [0.92082153, 0.53332395, 0.92132082, 0.17520147, 0.99507534],\n",
      "       [0.10735221, 0.31411439, 0.30251394, 0.53594764, 0.12447308],\n",
      "       [0.68624494, 0.75280091, 0.41812653, 0.86962729, 0.85441685]]), 'net': 0.5899930348224928, 'gradient': 0.5805115428601816}, {'weights': array([[0.13473796, 0.65617472, 0.41120276, 0.83237341, 0.50237475],\n",
      "       [0.54870562, 0.99707657, 0.95700988, 0.26915536, 0.12400468],\n",
      "       [0.93841573, 0.06903741, 0.20399664, 0.20801458, 0.30303735],\n",
      "       [0.91399644, 0.68890012, 0.92678883, 0.19238137, 0.46228665],\n",
      "       [0.87504043, 0.18732122, 0.44002853, 0.635078  , 0.99160945],\n",
      "       [0.19465479, 0.02870853, 0.88977292, 0.30691803, 0.67608771],\n",
      "       [0.42574876, 0.82533958, 0.80368951, 0.4344251 , 0.66711504],\n",
      "       [0.12014912, 0.9286774 , 0.23000819, 0.85580813, 0.3596215 ],\n",
      "       [0.0931416 , 0.55023203, 0.38531632, 0.15475824, 0.88812783],\n",
      "       [0.05731276, 0.72599015, 0.51906036, 0.47563973, 0.0283284 ]]), 'inputs': array([[0.64052705, 0.20058312, 0.87615717, 0.33062627, 0.94586443],\n",
      "       [0.01220238, 0.60828636, 0.69690808, 0.20703521, 0.7515457 ],\n",
      "       [0.40124558, 0.4753341 , 0.05642372, 0.30905669, 0.20263383],\n",
      "       [0.90235088, 0.9029878 , 0.53557335, 0.05145433, 0.3663919 ],\n",
      "       [0.46993647, 0.98688677, 0.90310186, 0.39802382, 0.22777314],\n",
      "       [0.12814474, 0.29220353, 0.34517431, 0.92762106, 0.16517613],\n",
      "       [0.03404194, 0.94519725, 0.20039914, 0.88323665, 0.0681365 ],\n",
      "       [0.51004312, 0.94597985, 0.25943378, 0.40893211, 0.28098157],\n",
      "       [0.62315243, 0.18969044, 0.85209781, 0.16301274, 0.36995315],\n",
      "       [0.26536456, 0.09215339, 0.04394849, 0.61601837, 0.54608904]]), 'net': 0.3533872582759594, 'gradient': 0.536675914972674}, {'weights': array([[0.5628954 , 0.92779281, 0.42947343, 0.08725319, 0.21613788,\n",
      "        0.13977937, 0.38503079, 0.19394485, 0.21367165, 0.33823905],\n",
      "       [0.60384175, 0.69342322, 0.23442622, 0.25343999, 0.31937033,\n",
      "        0.2640537 , 0.86261996, 0.88117205, 0.5494187 , 0.56318741],\n",
      "       [0.00337153, 0.74855922, 0.31793524, 0.21246379, 0.56906686,\n",
      "        0.49190789, 0.87713554, 0.52477264, 0.35146115, 0.75378501],\n",
      "       [0.20346872, 0.50384297, 0.91854145, 0.87059575, 0.30143017,\n",
      "        0.82232022, 0.928408  , 0.05467704, 0.28648085, 0.11400104]]), 'inputs': array([[0.31954218, 0.1374709 , 0.1240531 , 0.14774856, 0.53991344,\n",
      "        0.01291314, 0.9776629 , 0.59725359, 0.45793814, 0.79437154],\n",
      "       [0.28550511, 0.04170983, 0.89663309, 0.12442228, 0.15134777,\n",
      "        0.48638835, 0.02951173, 0.91199173, 0.38748512, 0.96582881],\n",
      "       [0.39709662, 0.16590152, 0.46571809, 0.8039343 , 0.27368976,\n",
      "        0.7633269 , 0.99697252, 0.63364129, 0.57157566, 0.71451576],\n",
      "       [0.90001126, 0.93531368, 0.29236514, 0.18148517, 0.11130094,\n",
      "        0.98558725, 0.09279915, 0.37391058, 0.14707929, 0.59271793]]), 'net': 0.2877392256024991, 'gradient': 0.46775275215881895}]\n",
      "[{'weights': array([[0.11876262],\n",
      "       [0.02701475],\n",
      "       [0.41985974],\n",
      "       [0.53088379],\n",
      "       [0.94699367]]), 'inputs': array([[1. ],\n",
      "       [7.2],\n",
      "       [3.2],\n",
      "       [6. ],\n",
      "       [1.8]]), 'net': 0.2915485209042714, 'gradient': 0.09250016210488632}, {'weights': array([[-0.26693318, -0.26693318, -0.26693318, -0.26693318, -0.26693318],\n",
      "       [16.01245404, 16.15981853, 16.31422315, 16.47220293, 15.91092319],\n",
      "       [14.49714833, 14.69303339, 14.6214278 , 14.58558654, 14.53545073],\n",
      "       [13.83096686, 13.49347519, 13.46515063, 14.18627446, 14.29323094],\n",
      "       [13.48108531, 13.61133337, 13.98189542, 14.39818721, 13.5091516 ]]), 'inputs': array([[1. ],\n",
      "       [7.2],\n",
      "       [3.2],\n",
      "       [6. ],\n",
      "       [1.8]]), 'net': [array([1.]), array([0.]), array([0.]), array([0.]), array([0.])], 'gradient': array([-26.69331845, -29.52917264, -29.17563433, -27.01284324,\n",
      "       -27.81993255])}, {'weights': array([[-0.01439903, -0.01439903, -0.01439903, -0.01439903, -0.01439903],\n",
      "       [ 2.0530257 ,  2.50139665,  2.46132996,  1.77347544,  1.62832475],\n",
      "       [ 1.3520938 ,  0.48271547,  0.6176747 ,  0.62169265,  0.71671542],\n",
      "       [ 1.36722875,  1.14213243,  1.38002114,  0.64561368,  0.91551896],\n",
      "       [ 2.23313579,  1.54541658,  1.79812388,  1.99317336,  2.34970481],\n",
      "       [ 0.81886648,  0.65292022,  1.51398461,  0.93112972,  1.3002994 ],\n",
      "       [ 1.59368144,  1.99327226,  1.97162219,  1.60235779,  1.83504772],\n",
      "       [ 2.27882904,  3.08735732,  2.38868812,  3.01448805,  2.51830142],\n",
      "       [ 1.59877858,  2.055869  ,  1.89095329,  1.66039522,  2.39376481],\n",
      "       [ 1.93750273,  2.60618011,  2.39925033,  2.3558297 ,  1.90851836]]), 'inputs': [array([1.]), array([0.]), array([0.]), array([0.]), array([0.])], 'net': [array([1.]), array([0.06148703]), array([0.23092572]), array([0.22509235]), array([0.04327724]), array([0.53551919]), array([0.14789327]), array([0.03941646]), array([0.14619313]), array([0.07626226])], 'gradient': array([-1.43990281, -1.88471625, -1.03939379, -0.98186803, -1.9076367 ,\n",
      "       -1.30958767, -1.58872754, -2.11009559, -1.7049803 , -2.27978397])}, {'weights': array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 1.50384175,  1.59342322,  1.13442622,  1.15343999,  1.21937033,\n",
      "         1.1640537 ,  1.76261996,  1.78117205,  1.4494187 ,  1.46318741],\n",
      "       [ 0.36337153,  1.10855922,  0.67793524,  0.57246379,  0.92906686,\n",
      "         0.85190789,  1.23713554,  0.88477264,  0.71146115,  1.11378501],\n",
      "       [-1.05653128, -0.75615703, -0.34145855, -0.38940425, -0.95856983,\n",
      "        -0.43767978, -0.331592  , -1.20532296, -0.97351915, -1.14599896]]), 'inputs': [array([1.]), array([0.06148703]), array([0.23092572]), array([0.22509235]), array([0.04327724]), array([0.53551919]), array([0.14789327]), array([0.03941646]), array([0.14619313]), array([0.07626226])], 'net': [array([1.]), array([0.00399161]), array([0.13844865]), array([0.08614731])], 'gradient': array([ 0.,  0., -1.,  1.])}]\n",
      "[[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0]]\n",
      "Testing accuracy:\n",
      " 33.33333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Menna\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1702, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-517-75233577d4ed>\", line 5, in submit_button_backpropagation\n",
      "    int(epochs_text.get()), int(bias_checkbox.get()))\n",
      "  File \"<ipython-input-508-18e3e383e7a4>\", line 20, in main\n",
      "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_prediction_test))\n",
      "  File \"C:\\Users\\Menna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 270, in confusion_matrix\n",
      "    raise ValueError(\"%s is not supported\" % y_type)\n",
      "ValueError: multilabel-indicator is not supported\n"
     ]
    }
   ],
   "source": [
    "input_window.mainloop() #open window"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "name": "NN Task 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
